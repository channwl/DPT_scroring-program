import streamlit as st
import random
import re
import io
import os
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import LLMChain
from langchain.memory import ConversationSummaryMemory
from langchain_core.prompts import PromptTemplate
import html
import pdfplumber

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AI ì±„ì  ì‹œìŠ¤í…œ", layout="wide")
st.title("ğŸ“ AI ê¸°ë°˜ ìë™ ì±„ì  ì‹œìŠ¤í…œ - by DPT")

# GPT ì´ˆê¸°í™”
llm = ChatOpenAI(
    openai_api_key=st.secrets["openai"]["API_KEY"],
    model_name="gpt-4o",
    temperature=0
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
def initialize_session_state():
    defaults = {
        "rubric_memory": ConversationSummaryMemory(
            llm=llm, memory_key="history", return_messages=True
        ),
        "step": 1,
        "generated_rubrics": {},
        "problem_text": None,
        "problem_filename": None,
        "student_answers_data": [],
        "feedback_text": "",
        "modified_rubrics": {},
        "last_grading_result": None,
        "last_selected_student": None,
        "all_grading_results": [],
        "highlighted_results": []
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

initialize_session_state()

# Prompt ë° ì²´ì¸ ì„¤ì •
prompt_template = PromptTemplate.from_template("{history}\n{input}")
rubric_chain = LLMChain(llm=llm, prompt=prompt_template, memory=st.session_state.rubric_memory)


# -------------------------------
# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜
# -------------------------------
def extract_text_from_pdf(pdf_data):
    if isinstance(pdf_data, bytes):
        pdf_stream = io.BytesIO(pdf_data)
    else:
        pdf_stream = io.BytesIO(pdf_data.read())

    text = ""
    with pdfplumber.open(pdf_stream) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"

    return text

# -------------------------------
# ì „ì²˜ë¦¬: ë¬¸ë‹¨ ì •ë¦¬ ë° ë¶ˆí•„ìš”í•œ ì¤„ ì œê±°
# -------------------------------
def clean_text_postprocess(text):
    lines = text.split('\n')
    cleaned = []
    prev_blank = True  # ë¬¸ë‹¨ ì‹œì‘ ì—¬ë¶€ ì²´í¬ìš©

    for line in lines:
        line = line.strip()
        # ìŠ¤í‚µí•  ì¤„: í˜ì´ì§€ ë²ˆí˜¸, ê³¼ì œ ì œëª©, í•™ë²ˆ ì¤„ ë“±
        if re.search(r'DIGB226|Final Take-Home Exam|^\s*-\s*\d+\s*-$', line):
            continue
        if re.search(r'^\d{9,10}\s*[\uAC00-\uD7A3]+$', line):
            continue
        if not line:
            prev_blank = True
            continue

        # ìƒˆ ë¬¸ë‹¨ ì‹œì‘ ì‹œ ë¹ˆ ì¤„ ì¶”ê°€
        if prev_blank:
            cleaned.append("")  # ë¹ˆ ì¤„ ë„£ê¸°
        cleaned.append(line)
        prev_blank = False

    return "\n".join(cleaned)


#íŒŒì¼ëª… ì¶”ì¶œ
def extract_info_from_filename(filename):
    base_filename = os.path.splitext(os.path.basename(filename))[0]
    id_match = re.search(r'\d{6,10}', base_filename)
    student_id = id_match.group() if id_match else "UnknownID"
    name_candidates = [part for part in re.findall(r'[ê°€-í£]{2,5}', base_filename) if part not in student_id]
    exclude_words = {"ê¸°ë§", "ì¤‘ê°„", "ê³¼ì œ", "ì‹œí—˜", "ìˆ˜ì—…", "ë ˆí¬íŠ¸", "ì œì¶œ", "ë‹µì•ˆ"}
    for name in name_candidates:
        if name not in exclude_words:
            return name, student_id
    return "UnknownName", student_id


# -------------------------------
# í•™ìƒ PDF ì²˜ë¦¬ í•¨ìˆ˜
# -------------------------------
def process_student_pdfs(pdf_files):
    answers, info = [], []
    for file in pdf_files:
        file.seek(0)
        file_bytes = file.read()

        # í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ ë¬¸ë‹¨ ì •ë¦¬ê¹Œì§€!
        text = extract_text_from_pdf(io.BytesIO(file_bytes))
        text = clean_text_postprocess(text)

        name, sid = extract_info_from_filename(file.name)
        if len(text.strip()) > 20:
            answers.append(text)
            info.append({'name': name, 'id': sid, 'text': text})

    st.session_state.student_answers_data = info
    return answers, info

#ë“¤ì—¬ì“°ê¸° ì²˜ë¦¬
def apply_indentation(text):
    lines = text.split('\n')
    html_lines = []
    for line in lines:
        line = line.strip()
        if not line:
            html_lines.append("<br>")
            continue
        if re.match(r'^\d+(\.\d+)*\s', line):  # 1. / 1.1 / 2. ê°™ì€ ì œëª©
            html_lines.append(f"<p style='margin-bottom: 5px; font-weight: bold;'>{html.escape(line)}</p>")
        else:
            html_lines.append(f"<p style='padding-left: 20px; margin: 0;'>{html.escape(line)}</p>")
    return "\n".join(html_lines)

# ì´ì  ì¶”ì¶œ í•¨ìˆ˜
def extract_total_score(grading_text):
    match = re.search(r'ì´ì [:ï¼š]?\s*(\d+)\s*ì ', grading_text)
    return int(match.group(1)) if match else None

from difflib import get_close_matches
import html

def apply_highlight_fuzzy(text, evidences, threshold=0.75):
    """
    í•™ìƒ ë‹µì•ˆì—ì„œ ì¦ê±° ë¬¸ì¥ì„ fuzzyí•˜ê²Œ ë§¤ì¹­í•˜ì—¬ í•˜ì´ë¼ì´íŒ…í•˜ëŠ” í•¨ìˆ˜

    Args:
        text (str): ì „ì²´ í•™ìƒ ë‹µì•ˆ í…ìŠ¤íŠ¸
        evidences (list of str): ì±„ì  ê¸°ì¤€ì—ì„œ ì¶”ì¶œëœ ì¦ê±° ë¬¸ì¥ë“¤
        threshold (float): ìœ ì‚¬ë„ ë§¤ì¹­ ê¸°ì¤€ (0~1)

    Returns:
        str: HTML í˜•ì‹ìœ¼ë¡œ í•˜ì´ë¼ì´íŒ…ëœ í…ìŠ¤íŠ¸
    """
    lines = text.split('\n')
    used_indices = set()
    html_lines = []

    for line in lines:
        matched = False
        for idx, evidence in enumerate(evidences):
            matches = get_close_matches(evidence.strip(), [line.strip()], n=1, cutoff=threshold)
            if matches and idx not in used_indices:
                used_indices.add(idx)
                color = ["#FFD6D6", "#D6FFD6", "#D6D6FF", "#FFFFD6", "#FFD6FF", "#D6FFFF"][idx % 6]
                safe_line = html.escape(line)
                highlighted = f'<span style="background-color:{color}; padding:2px; border-radius:3px;">{safe_line}</span>'
                html_lines.append(highlighted)
                matched = True
                break
        if not matched:
            html_lines.append(html.escape(line))

    return "<br>".join(html_lines)


# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.markdown("## \U0001F4D8 ì±„ì  íë¦„")

    if st.button("1ï¸âƒ£ ë¬¸ì œ ì—…ë¡œë“œ ë° ì±„ì  ê¸°ì¤€ ìƒì„±"):
        st.session_state.step = 1
    if st.button("2ï¸âƒ£ í•™ìƒ ë‹µì•ˆ ì—…ë¡œë“œ ë° ë¬´ì‘ìœ„ ì±„ì "):
        st.session_state.step = 2
    if st.button("3ï¸âƒ£ êµìˆ˜ì í”¼ë“œë°± ì…ë ¥"):
        st.session_state.step = 3
    if st.button("4ï¸âƒ£ ì „ì²´ í•™ìƒ ì¼ê´„ ì±„ì "):
        st.session_state.step = 4

    st.markdown("### \U0001F4DD êµìˆ˜ì í”¼ë“œë°±")
    feedback = st.text_area("ì±„ì  ê¸°ì¤€ ìˆ˜ì • í”¼ë“œë°±", value=st.session_state.feedback_text, key="sidebar_feedback")
    st.session_state.feedback_text = feedback

    with st.expander("â„¹ï¸ ì‚¬ìš©ë²• ì•ˆë‚´ ë³´ê¸°"):
        st.markdown("""
**STEP 1:** ë¬¸ì œ ì—…ë¡œë“œ â†’ ì±„ì  ê¸°ì¤€ ìƒì„±  
**STEP 2:** í•™ìƒ ë‹µì•ˆ ì—…ë¡œë“œ â†’ ë¬´ì‘ìœ„ ì±„ì   
**STEP 3:** êµìˆ˜ì í”¼ë“œë°± â†’ ê¸°ì¤€ ìˆ˜ì •  
**STEP 4:** ì „ì²´ í•™ìƒ ìë™ ì±„ì  + í•˜ì´ë¼ì´íŒ…
""")

# STEP 1 - ë¬¸ì œ ì—…ë¡œë“œ -> ì±„ì  ê¸°ì¤€ ìƒì„±
if st.session_state.step == 1:
    problem_pdf = st.file_uploader("ğŸ“„ ë¬¸ì œ PDF ì—…ë¡œë“œ", type="pdf", key="problem_upload")

    if problem_pdf:
        # PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë‚´ìš©ê³¼ íŒŒì¼ëª…ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        file_bytes = problem_pdf.read()
        st.session_state.problem_pdf_bytes = file_bytes
        st.session_state.problem_filename = problem_pdf.name
        text = extract_text_from_pdf(io.BytesIO(file_bytes))
        st.session_state.problem_text = text
        
        rubric_key = f"rubric_{problem_pdf.name}"

        st.subheader("ğŸ“ƒ ë¬¸ì œ ë‚´ìš©")
        st.write(text)

        # ì´ë¯¸ ìƒì„±ëœ ì±„ì  ê¸°ì¤€ì´ ìˆëŠ”ì§€ í™•ì¸
        if rubric_key not in st.session_state.generated_rubrics:
            prompt = f"""ë‹¤ìŒ ë¬¸ì œì— ëŒ€í•œ ì±„ì  ê¸°ì¤€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš” (ë°˜ë“œì‹œ **í•œê¸€**ë¡œ ì‘ì„±):

ë¬¸ì œ: {text}

ìš”êµ¬ì‚¬í•­:
1. í‘œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš” (ì •í™•íˆ '| ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |' í˜•ì‹ì˜ ë§ˆí¬ë‹¤ìš´ í‘œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”)
2. ê° í•­ëª©ì˜ ì„¸ë¶€ ê¸°ì¤€ì€ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
3. ì„¤ëª…ì€ ë°˜ë“œì‹œ **í•œê¸€**ë¡œ ì‘ì„±í•´ì•¼ í•˜ë©°, ì˜ì–´ í˜¼ìš© ì—†ì´ ì‘ì„±í•´ì£¼ì„¸ìš”
4. í‘œ ì•„ë˜ì— **ë°°ì  ì´í•©**ë„ í•¨ê»˜ ì‘ì„±í•´ì£¼ì„¸ìš”
5. ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ ë¬¸ë²•ì„ ì •í™•íˆ ì‚¬ìš©í•´ì£¼ì„¸ìš”, (ê° í–‰ ì‹œì‘ê³¼ ëì— |, í—¤ë” í–‰ ì•„ë˜ì— |---|---|---| í˜•ì‹ì˜ êµ¬ë¶„ì„ )

ì˜ˆì‹œ í˜•ì‹:
| ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |
|---------|-----|---------|
| í•­ëª© 1 | 5ì  | ì„¸ë¶€ ê¸°ì¤€ ì„¤ëª… |
| í•­ëª© 2 | 10ì  | ì„¸ë¶€ ê¸°ì¤€ ì„¤ëª… |

**ë°°ì  ì´í•©: 15ì **
"""
            if st.button("ğŸ“ ì±„ì  ê¸°ì¤€ ìƒì„±"):
                # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”í•˜ì—¬ ì´ì „ ëŒ€í™”ê°€ ì˜í–¥ì„ ì£¼ì§€ ì•Šë„ë¡ í•¨
                st.session_state.rubric_memory.clear()
                
                with st.spinner("GPTê°€ ì±„ì  ê¸°ì¤€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    result = rubric_chain.invoke({"input": prompt})
                    # ìƒì„±ëœ ì±„ì  ê¸°ì¤€ì„ ë³„ë„ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥
                    st.session_state.generated_rubrics[rubric_key] = result["text"]
                    st.success("âœ… ì±„ì  ê¸°ì¤€ ìƒì„± ì™„ë£Œ")
        else:
            if st.button("ğŸ“ ì±„ì  ê¸°ì¤€ ì¬ìƒì„±"):
                confirm = st.checkbox("âš ï¸ ì´ë¯¸ ìƒì„±ëœ ì±„ì  ê¸°ì¤€ì´ ìˆìŠµë‹ˆë‹¤. ì¬ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
                if confirm:
                    # ì—¬ê¸°ì„œëŠ” ëª…ì‹œì ìœ¼ë¡œ ì‚¬ìš©ìê°€ ì¬ìƒì„±ì„ ì›í•  ë•Œë§Œ ì²˜ë¦¬
                    prompt = f"""ë‹¤ìŒ ë¬¸ì œì— ëŒ€í•œ ì±„ì  ê¸°ì¤€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš” (ë°˜ë“œì‹œ **í•œê¸€**ë¡œ ì‘ì„±):

ë¬¸ì œ: {text}

ìš”êµ¬ì‚¬í•­:
1. í‘œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš” (ì •í™•íˆ '| ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |' í˜•ì‹ì˜ ë§ˆí¬ë‹¤ìš´ í‘œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”)
2. ê° í•­ëª©ì˜ ì„¸ë¶€ ê¸°ì¤€ì€ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
3. ì„¤ëª…ì€ ë°˜ë“œì‹œ **í•œê¸€**ë¡œ ì‘ì„±í•´ì•¼ í•˜ë©°, ì˜ì–´ í˜¼ìš© ì—†ì´ ì‘ì„±í•´ì£¼ì„¸ìš”
4. í‘œ ì•„ë˜ì— **ë°°ì  ì´í•©**ë„ í•¨ê»˜ ì‘ì„±í•´ì£¼ì„¸ìš”
5. ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ ë¬¸ë²•ì„ ì •í™•íˆ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤ (ê° í–‰ ì‹œì‘ê³¼ ëì— |, í—¤ë” í–‰ ì•„ë˜ì— |---|---|---| í˜•ì‹ì˜ êµ¬ë¶„ì„ )

ì˜ˆì‹œ í˜•ì‹:
| ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |
|---------|-----|---------|
| í•­ëª© 1 | 5ì  | ì„¸ë¶€ ê¸°ì¤€ ì„¤ëª… |
| í•­ëª© 2 | 10ì  | ì„¸ë¶€ ê¸°ì¤€ ì„¤ëª… |

**ë°°ì  ì´í•©: 15ì **
"""
                    st.session_state.rubric_memory.clear()
                    with st.spinner("GPTê°€ ì±„ì  ê¸°ì¤€ì„ ì¬ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                        result = rubric_chain.invoke({"input": prompt})
                        st.session_state.generated_rubrics[rubric_key] = result["text"]
                        st.success("âœ… ì±„ì  ê¸°ì¤€ ì¬ìƒì„± ì™„ë£Œ")

        # ì±„ì  ê¸°ì¤€ í‘œì‹œ
        if rubric_key in st.session_state.generated_rubrics:
            st.subheader("ğŸ“Š ì±„ì  ê¸°ì¤€")
            st.markdown(st.session_state.generated_rubrics[rubric_key])

# STEP 2 - í•™ìƒ ë‹µì•ˆ -> ë¬´ì‘ìœ„ ì±„ì 
elif st.session_state.step == 2:
    # ë¬¸ì œê°€ ì´ë¯¸ ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
    if st.session_state.problem_text and st.session_state.problem_filename:
        st.subheader("ğŸ“ƒ ë¬¸ì œ ë‚´ìš©")
        st.write(st.session_state.problem_text)
        
        rubric_key = f"rubric_{st.session_state.problem_filename}"
        if rubric_key in st.session_state.generated_rubrics:
            st.subheader("ğŸ“Š ì±„ì  ê¸°ì¤€")
            st.markdown(st.session_state.generated_rubrics[rubric_key])
        
        student_pdfs = st.file_uploader("ğŸ“¥ í•™ìƒ ë‹µì•ˆ PDF ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ)", type="pdf", accept_multiple_files=True, key="student_answers")
        
        if student_pdfs:
            if rubric_key not in st.session_state.generated_rubrics:
                st.warning("ì±„ì  ê¸°ì¤€ì´ ì—†ìŠµë‹ˆë‹¤. STEP 1ì—ì„œ ë¨¼ì € ì±„ì  ê¸°ì¤€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
            else:
                if st.button("ğŸ¯ ë¬´ì‘ìœ„ ì±„ì  ì‹¤í–‰"):
                    all_answers, info_list = process_student_pdfs(student_pdfs)
                    if not all_answers:
                        st.warning("ë‹µì•ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        idx = random.randint(0, len(all_answers) - 1)
                        selected_student = info_list[idx]
                        answer = all_answers[idx]

                        prompt = f"""ë‹¤ìŒì€ ì±„ì  ê¸°ì¤€ì…ë‹ˆë‹¤:
{st.session_state.generated_rubrics[rubric_key]}

ê·¸ë¦¬ê³  ì•„ë˜ëŠ” í•™ìƒ ë‹µì•ˆì…ë‹ˆë‹¤:
{answer}

ì´ ê¸°ì¤€ì— ë”°ë¼ ì±„ì  í‘œë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”:
ë°˜ë“œì‹œ ë‹¤ìŒê³¼ ê°™ì€ ì •í™•í•œ ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”:

| ì±„ì  í•­ëª© | ë°°ì  | GPT ì¶”ì²œ ì ìˆ˜ | ì„¸ë¶€ í‰ê°€ |
|---------|-----|------------|---------|
| í•­ëª© 1 | 5ì  | 4ì  | í‰ê°€ ë‚´ìš© |

í‘œ ì•„ë˜ì— ì´ì ê³¼ ê°„ë‹¨í•œ í”¼ë“œë°±ë„ ì‘ì„±í•´ì£¼ì„¸ìš”."""

                        with st.spinner("GPTê°€ ì±„ì  ì¤‘ì…ë‹ˆë‹¤..."):
                            # ì±„ì ì—ëŠ” ë©”ëª¨ë¦¬ê°€ í•„ìš”í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë³„ë„ ì²´ì¸ì„ ë§Œë“¤ì–´ ì‚¬ìš©
                            grading_chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template("{input}"))
                            result = grading_chain.invoke({"input": prompt})
                            st.session_state.last_grading_result = result["text"]
                            st.session_state.last_selected_student = selected_student
                            st.success("âœ… ì±„ì  ì™„ë£Œ")
    else:
        st.warning("ë¨¼ì € STEP 1ì—ì„œ ë¬¸ì œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        if st.button("STEP 1ë¡œ ì´ë™"):
            st.session_state.step = 1

    # ì±„ì  ê²°ê³¼ í‘œì‹œ
    if st.session_state.last_grading_result and st.session_state.last_selected_student:
        stu = st.session_state.last_selected_student
        st.subheader(f"ğŸ“‹ ì±„ì  ê²°ê³¼ - {stu['name']} ({stu['id']})")
        st.markdown(st.session_state.last_grading_result)

# STEP 3 : êµìˆ˜ì í”¼ë“œë°± -> ì±„ì  ê¸°ì¤€ ìˆ˜ì •
elif st.session_state.step == 3:
    # ë¬¸ì œê°€ ì´ë¯¸ ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
    if st.session_state.problem_text and st.session_state.problem_filename:
        rubric_key = f"rubric_{st.session_state.problem_filename}"
        
        if rubric_key not in st.session_state.generated_rubrics:
            st.warning("ì±„ì  ê¸°ì¤€ì´ ì—†ìŠµë‹ˆë‹¤. STEP 1ì—ì„œ ë¨¼ì € ì±„ì  ê¸°ì¤€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
            if st.button("STEP 1ë¡œ ì´ë™"):
                st.session_state.step = 1
        else:
            # ì›ë³¸ ì±„ì  ê¸°ì¤€ í‘œì‹œ
            st.subheader("ğŸ“Š ì›ë³¸ ì±„ì  ê¸°ì¤€")
            st.markdown(st.session_state.generated_rubrics[rubric_key])
            
            if st.button("â™»ï¸ í”¼ë“œë°± ë°˜ì˜"):
                feedback = st.session_state.feedback_text
                if not feedback.strip():
                    st.warning("í”¼ë“œë°±ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    prompt = f"""ê¸°ì¡´ ì±„ì  ê¸°ì¤€:
{st.session_state.generated_rubrics[rubric_key]}

í”¼ë“œë°±:
{feedback}

ìš”êµ¬ì‚¬í•­:
1. í‘œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš” (ì •í™•íˆ '| ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |' í˜•ì‹ì˜ ë§ˆí¬ë‹¤ìš´ í‘œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”)
2. ê° í•­ëª©ì˜ ì„¸ë¶€ ê¸°ì¤€ì€ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
3. ì„¤ëª…ì€ ë°˜ë“œì‹œ **í•œê¸€**ë¡œ ì‘ì„±í•´ì•¼ í•˜ë©°, ì˜ì–´ í˜¼ìš© ì—†ì´ ì‘ì„±í•´ì£¼ì„¸ìš”
4. í‘œ ì•„ë˜ì— **ë°°ì  ì´í•©**ë„ í•¨ê»˜ ì‘ì„±í•´ì£¼ì„¸ìš”
5. ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ ë¬¸ë²•ì„ ì •í™•íˆ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤ (ê° í–‰ ì‹œì‘ê³¼ ëì— |, í—¤ë” í–‰ ì•„ë˜ì— |---|---|---| í˜•ì‹ì˜ êµ¬ë¶„ì„ )

ì˜ˆì‹œ í˜•ì‹:
| ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |
|---------|-----|---------|
| í•­ëª© 1 | 5ì  | ì„¸ë¶€ ê¸°ì¤€ ì„¤ëª… |
| í•­ëª© 2 | 10ì  | ì„¸ë¶€ ê¸°ì¤€ ì„¤ëª… |

**ë°°ì  ì´í•©: 15ì **
"""
                
                    with st.spinner("GPTê°€ ê¸°ì¤€ì„ ìˆ˜ì • ì¤‘ì…ë‹ˆë‹¤..."):
                        # í”¼ë“œë°± ë°˜ì˜ì—ë„ ë³„ë„ ì²´ì¸ ì‚¬ìš©
                        feedback_chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template("{input}"))
                        updated = feedback_chain.invoke({"input": prompt})
                        st.session_state.modified_rubrics[rubric_key] = updated["text"]
                        st.success("âœ… ì±„ì  ê¸°ì¤€ ìˆ˜ì • ì™„ë£Œ")
                
            # ìˆ˜ì •ëœ ì±„ì  ê¸°ì¤€ì´ ìˆìœ¼ë©´ í‘œì‹œ
            if rubric_key in st.session_state.modified_rubrics:
                st.subheader("ğŸ†• ìˆ˜ì •ëœ ì±„ì  ê¸°ì¤€")
                st.markdown(st.session_state.modified_rubrics[rubric_key])
    else:
        st.warning("ë¨¼ì € STEP 1ì—ì„œ ë¬¸ì œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        if st.button("STEP 1ë¡œ ì´ë™"):
            st.session_state.step = 1

# STEP 4 - ì „ì²´ í•™ìƒ ì±„ì  ë° ê·¼ê±° ë¬¸ì¥ í™•ì¸
elif st.session_state.step == 4:
    rubric_key = f"rubric_{st.session_state.problem_filename}"
    
    # ìµœì¢… ì±„ì  ê¸°ì¤€ (ìˆ˜ì •ëœ ê²ƒì´ ìˆìœ¼ë©´ ìˆ˜ì •ëœ ê²ƒ, ì—†ìœ¼ë©´ ì›ë³¸)
    rubric_text = st.session_state.modified_rubrics.get(rubric_key, st.session_state.generated_rubrics.get(rubric_key))

    if not rubric_text:
        st.warning("ì±„ì  ê¸°ì¤€ì´ ì—†ìŠµë‹ˆë‹¤. STEP 1ì„ ë¨¼ì € ì§„í–‰í•˜ì„¸ìš”.")
    elif not st.session_state.student_answers_data:
        st.warning("í•™ìƒ ë‹µì•ˆì´ ì—†ìŠµë‹ˆë‹¤. STEP 2ë¥¼ ë¨¼ì € ì§„í–‰í•˜ì„¸ìš”.")
    else:
        st.subheader("ğŸ“Š ì±„ì  ê¸°ì¤€")
        st.markdown(rubric_text)

        if st.button("ğŸ“ ì „ì²´ í•™ìƒ ì±„ì  ì‹¤í–‰"):
            st.session_state.highlighted_results = []
            progress_bar = st.progress(0)
            total_students = len(st.session_state.student_answers_data)
            
            with st.spinner("GPTê°€ ì±„ì  ì¤‘ì…ë‹ˆë‹¤..."):
                for i, student in enumerate(st.session_state.student_answers_data):
                    name, sid, answer = student["name"], student["id"], student["text"]
                    
                    # GPT ì±„ì  í”„ë¡¬í”„íŠ¸
                    prompt = f"""
ë‹¤ìŒì€ ì±„ì  ê¸°ì¤€ì…ë‹ˆë‹¤:
ë‹¤ìŒì€ ì±„ì  ê¸°ì¤€ì…ë‹ˆë‹¤:
{rubric_text}

ì•„ë˜ëŠ” í•™ìƒ({name}, {sid})ì˜ ë‹µì•ˆì…ë‹ˆë‹¤:
{answer}

---

ì±„ì ì„ ì§„í–‰í•˜ê¸° ì „ì— ì˜ˆì‹œë¥¼ ë¨¼ì € í™•ì¸í•˜ì„¸ìš”:

=============================  
[ì˜ˆì‹œ ì±„ì  ê¸°ì¤€]

| ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |
|----------|-----|-----------|
| ì¸ê³µì‹ ê²½ë§(ANN)ì˜ ê¸°ë³¸ ê°œë… ì„¤ëª… | 5ì  | ë‰´ëŸ°, ê°€ì¤‘ì¹˜, í™œì„±í™” í•¨ìˆ˜ ë“±ì˜ ê°œë…ì„ í¬í•¨í•´ ì„¤ëª…í–ˆëŠ”ê°€ |
| ë”¥ëŸ¬ë‹ê³¼ ë¨¸ì‹ ëŸ¬ë‹ì˜ ì°¨ì´ ì„¤ëª… | 5ì  | íŠ¹ì§• ë˜ëŠ” í•™ìŠµ ë°©ì‹ì˜ ì°¨ì´ë¥¼ ëª…í™•íˆ ì„œìˆ í–ˆëŠ”ê°€ |
| ì—­ì „íŒŒ ì•Œê³ ë¦¬ì¦˜ì˜ ì‘ë™ ì›ë¦¬ ì„¤ëª… | 10ì  | ì˜¤ì°¨ ê³„ì‚° â†’ ê°€ì¤‘ì¹˜ ê°±ì‹  ê³¼ì •ì„ ë‹¨ê³„ì ìœ¼ë¡œ ì„¤ëª…í–ˆëŠ”ê°€ |

[ì˜ˆì‹œ í•™ìƒ ë‹µì•ˆ]

ë”¥ëŸ¬ë‹ì€ ì¸ê³µì‹ ê²½ë§ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ í•™ìŠµ ë°©ì‹ì´ë‹¤.  
ANNì€ ì…ë ¥ì„ ë°›ì•„ ê°€ì¤‘ì¹˜ë¥¼ ê³±í•œ í›„, í™œì„±í™” í•¨ìˆ˜ë¥¼ ê±°ì³ ì¶œë ¥ì„ ìƒì„±í•œë‹¤.  
ë¨¸ì‹ ëŸ¬ë‹ì€ ì‚¬ëŒì´ íŠ¹ì§•ì„ ì„¤ê³„í•´ì•¼ í•˜ì§€ë§Œ, ë”¥ëŸ¬ë‹ì€ ìŠ¤ìŠ¤ë¡œ íŠ¹ì§•ì„ í•™ìŠµí•œë‹¤.  
ì—­ì „íŒŒëŠ” ì¶œë ¥ê³¼ ì‹¤ì œê°’ì˜ ì˜¤ì°¨ë¥¼ ê³„ì‚°í•œ ë’¤, ê·¸ ì˜¤ì°¨ë¥¼ ë„¤íŠ¸ì›Œí¬ì˜ ê°€ì¤‘ì¹˜ì— ë”°ë¼ ì—­ìœ¼ë¡œ ì „ë‹¬í•˜ë©° í•™ìŠµí•œë‹¤.  

[ì˜ˆì‹œ ì±„ì  ê²°ê³¼]

| ì±„ì  í•­ëª© | ë°°ì  | ë¶€ì—¬ ì ìˆ˜ | í‰ê°€ ê·¼ê±° |
|-------------------------|------|------------|--------------------------|
| ì¸ê³µì‹ ê²½ë§(ANN)ì˜ ê¸°ë³¸ ê°œë… ì„¤ëª… | 5ì  | 5ì  | "ANNì€ ì…ë ¥ì„ ë°›ì•„ ê°€ì¤‘ì¹˜ë¥¼ ê³±í•œ í›„, í™œì„±í™” í•¨ìˆ˜ë¥¼ ê±°ì³ ì¶œë ¥ì„ ìƒì„±í•œë‹¤."  
| ë”¥ëŸ¬ë‹ê³¼ ë¨¸ì‹ ëŸ¬ë‹ì˜ ì°¨ì´ ì„¤ëª… | 5ì  | 5ì  | "ë¨¸ì‹ ëŸ¬ë‹ì€ ì‚¬ëŒì´ íŠ¹ì§•ì„ ì„¤ê³„í•´ì•¼ í•˜ì§€ë§Œ, ë”¥ëŸ¬ë‹ì€ ìŠ¤ìŠ¤ë¡œ íŠ¹ì§•ì„ í•™ìŠµí•œë‹¤."  
| ì—­ì „íŒŒ ì•Œê³ ë¦¬ì¦˜ì˜ ì‘ë™ ì›ë¦¬ ì„¤ëª… | 10ì  | 10ì  | "ì—­ì „íŒŒëŠ” ì¶œë ¥ê³¼ ì‹¤ì œê°’ì˜ ì˜¤ì°¨ë¥¼ ê³„ì‚°í•œ ë’¤, ê·¸ ì˜¤ì°¨ë¥¼ ë„¤íŠ¸ì›Œí¬ì˜ ê°€ì¤‘ì¹˜ì— ë”°ë¼ ì—­ìœ¼ë¡œ ì „ë‹¬í•˜ë©° í•™ìŠµí•œë‹¤."  

**ê·¼ê±° ë¬¸ì¥:**
- "ANNì€ ì…ë ¥ì„ ë°›ì•„ ê°€ì¤‘ì¹˜ë¥¼ ê³±í•œ í›„, í™œì„±í™” í•¨ìˆ˜ë¥¼ ê±°ì³ ì¶œë ¥ì„ ìƒì„±í•œë‹¤."
- "ë¨¸ì‹ ëŸ¬ë‹ì€ ì‚¬ëŒì´ íŠ¹ì§•ì„ ì„¤ê³„í•´ì•¼ í•˜ì§€ë§Œ, ë”¥ëŸ¬ë‹ì€ ìŠ¤ìŠ¤ë¡œ íŠ¹ì§•ì„ í•™ìŠµí•œë‹¤."
- "ì—­ì „íŒŒëŠ” ì¶œë ¥ê³¼ ì‹¤ì œê°’ì˜ ì˜¤ì°¨ë¥¼ ê³„ì‚°í•œ ë’¤, ê·¸ ì˜¤ì°¨ë¥¼ ë„¤íŠ¸ì›Œí¬ì˜ ê°€ì¤‘ì¹˜ì— ë”°ë¼ ì—­ìœ¼ë¡œ ì „ë‹¬í•˜ë©° í•™ìŠµí•œë‹¤."

**ì´ì : 20ì **  
**ì´í‰:** í•™ìƒì€ ì£¼ìš” ê°œë…ì„ ëª¨ë‘ ì •í™•íˆ ì´í•´í•˜ê³  ì„œìˆ í•˜ì˜€ë‹¤.

=============================

ìœ„ì™€ ê°™ì€ í˜•ì‹ì„ ì°¸ê³ í•˜ì—¬, ì•„ë˜ì˜ ì‹¤ì œ í•™ìƒ ë‹µì•ˆì— ëŒ€í•´ ì±„ì ì„ ì§„í–‰í•´ì£¼ì„¸ìš”.

âš ï¸ ì£¼ì˜ì‚¬í•­:
- ê·¼ê±° ë¬¸ì¥ì€ ë°˜ë“œì‹œ í•™ìƒì´ ì‹¤ì œ ì‘ì„±í•œ ë¬¸ì¥ì—ì„œ ê·¸ëŒ€ë¡œ ë°œì·Œí•´ì•¼ í•©ë‹ˆë‹¤.
- ìš”ì•½, ì˜ì—­, ì¬êµ¬ì„± ì—†ì´ "ì›ë¬¸ ê·¸ëŒ€ë¡œ"ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
- í‰ê°€ ê·¼ê±°ëŠ” ì±„ì  í•­ëª©ë³„ë¡œ ëª…í™•íˆ ì—°ê²°ë˜ì–´ì•¼ í•˜ë©°, êµ¬ì²´ì ì¸ ë¬¸ì¥ì„ ë“¤ì–´ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤.

---

ì´ì œ ì•„ë˜ ì‹¤ì œ í•™ìƒ ë‹µì•ˆì„ í‰ê°€í•˜ì„¸ìš”:

[ì‹¤ì œ ì±„ì  ì‹œì‘ â†“â†“â†“]
"""
                    
                    # ì±„ì  ì‹¤í–‰
                    grading_chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template("{input}"))
                    result = grading_chain.invoke({"input": prompt})
                    grading_result = result["text"]
                    
                    # ê·¼ê±° ë¬¸ì¥ ì¶”ì¶œ
                    evidence_sentences = []
                    evidence_match = re.search(r'\*\*ê·¼ê±° ë¬¸ì¥:\*\*\s*([\s\S]*?)(?=\*\*ì´ì |\Z)', grading_result)
                    if evidence_match:
                        evidence_text = evidence_match.group(1)
                        for line in evidence_text.split('\n'):
                            match = re.search(r'"(.*?)"', line)
                            if match:
                                evidence_sentences.append(match.group(1))
                    
                    # ì´ì  ì¶”ì¶œ
                    total_score = None
                    score_match = re.search(r'\*\*ì´ì : (\d+)ì \*\*', grading_result)
                    if score_match:
                        total_score = int(score_match.group(1))
                    
                    # ì´í‰ ì¶”ì¶œ
                    feedback = ""
                    feedback_match = re.search(r'\*\*ì´í‰:\*\* (.*?)(?=\Z|\n\n)', grading_result)
                    if feedback_match:
                        feedback = feedback_match.group(1)
                    
                    # ê²°ê³¼ ì €ì¥ (í•˜ì´ë¼ì´íŒ… ì œì™¸)
                    st.session_state.highlighted_results.append({
                        "name": name,
                        "id": sid,
                        "score": total_score,
                        "feedback": feedback,
                        "grading_result": grading_result,
                        "original_text": answer,
                        "evidence_sentences": evidence_sentences
                    })
                    
                    progress_bar.progress((i + 1) / total_students)
            
            st.success(f"âœ… ì „ì²´ {total_students}ëª… í•™ìƒ ì±„ì  ì™„ë£Œ!")

        # ì±„ì  ê²°ê³¼ í‘œì‹œ
        if st.session_state.highlighted_results:
            # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
            sorted_results = sorted(
                st.session_state.highlighted_results, 
                key=lambda x: x["score"] if x["score"] is not None else 0,
                reverse=True
            )
            
            st.subheader("ğŸ“‹ ì „ì²´ í•™ìƒ ì±„ì  ê²°ê³¼")

            # ìš”ì•½ í…Œì´ë¸”
            summary_data = [
                {"ì´ë¦„": r["name"], "í•™ë²ˆ": r["id"], "ì ìˆ˜": r["score"] if r["score"] is not None else "N/A"} 
                for r in sorted_results
            ]
            
            st.subheader("ğŸ“Š í•™ìƒë³„ ì ìˆ˜ ìš”ì•½")
            st.table(summary_data)
            
            # ê° í•™ìƒë³„ ìƒì„¸ ê²°ê³¼
            st.subheader("ğŸ“ í•™ìƒë³„ ìƒì„¸ ë‹µì•ˆ ë° ì±„ì ")

            for idx, result in enumerate(sorted_results):
                with st.expander(f"ğŸ“„ {result['name']} ({result['id']}) - {result['score']}ì "):
                    tab1, tab2, tab3 = st.tabs(["ğŸ” ì±„ì  ê·¼ê±° ë¬¸ì¥", "ğŸ“‘ ì±„ì  ê²°ê³¼", "ğŸ“˜ ì›ë³¸ ë‹µì•ˆ"])

                    with tab1:
                        st.markdown("**GPTê°€ ì„ íƒí•œ í‰ê°€ ê·¼ê±° ë¬¸ì¥ì…ë‹ˆë‹¤.**")
                        if result["evidence_sentences"]:
                            for i, sentence in enumerate(result["evidence_sentences"], 1):
                                st.markdown(f"- **{i}.** {sentence}")
                        else:
                            st.info("ê·¼ê±° ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")

                    with tab2:
                        st.markdown("**GPT ì±„ì  ê²°ê³¼**")
                        st.markdown(result["grading_result"])

                    with tab3:
                        st.markdown("**ğŸ“„ ë¬¸ë‹¨ êµ¬ì¡°ë¡œ ì •ë¦¬ëœ ë‹µì•ˆ**")
                        formatted = apply_indentation(result["original_text"])
                        st.markdown(formatted, unsafe_allow_html=True)
