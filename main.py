import streamlit as st
import PyPDF2
import random
import re
import io
import os
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import LLMChain
from langchain.memory import ConversationSummaryMemory
from langchain_core.prompts import PromptTemplate

#Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AI ì±„ì  ì‹œìŠ¤í…œ", layout="wide")
st.title("ğŸ“ AI ê¸°ë°˜ ìë™ ì±„ì  ì‹œìŠ¤í…œ - by DPT")


# GPT ì—°ê²° ë° ì´ˆê¸°í™”
llm = ChatOpenAI(
    openai_api_key=st.secrets["openai"]["API_KEY"],
    model_name="gpt-4o",
    temperature=0
)

#ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” í•¨ìˆ˜
#í˜ì´ì§€ê°€ ìƒˆë¡œê³ ì¹¨ ë ë•Œë§ˆë‹¤ ë³€ìˆ˜ë¥¼ ìƒì–´ë²„ë¦¬ê¸° ë•Œë¬¸ì—, ë‹¤ìŒê³¼ ê°™ì€ ë³€ìˆ˜ë¥¼ session_stateì— ë„£ì–´ì¤Œ
#ê°’ì´ ìœ ì§€ë˜ëŠ” ê²°ê³¼ê°€ ë‚˜íƒ€ë‚¨
def initialize_session_state():
    defaults = {
        "rubric_memory": ConversationSummaryMemory(
            llm=llm, memory_key="history", return_messages=True
        ),
        "step": 1,
        "generated_rubrics": {},
        "problem_text": None,
        "problem_filename": None,
        "student_answers_data": [],
        "feedback_text": "",
        "modified_rubrics": {},
        "last_grading_result": None,
        "last_selected_student": None
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value #ì´ ë¶€ë¶„
            
initialize_session_state()

#LangChain í”„ë¡¬í¬íŠ¸ ë° ì²´ì¸ ì„¤ì •
#rubric_chain : ì±„ì  ê¸°ì¤€ì„ ìƒì„±í• ë•Œ ì‚¬ìš©í•˜ëŠ” ì²´ì¸
prompt_template = PromptTemplate.from_template("{history}\n{input}")
rubric_chain = LLMChain(
    llm=llm,
    prompt=prompt_template,
    memory=st.session_state.rubric_memory
)

# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
def extract_text_from_pdf(pdf_data):
    if isinstance(pdf_data, bytes):
        reader = PyPDF2.PdfReader(io.BytesIO(pdf_data))
    else:
        reader = PyPDF2.PdfReader(io.BytesIO(pdf_data.read()))
    return "".join([page.extract_text() or "" for page in reader.pages])

#íŒŒì¼ ì´ë¦„ ì¶”ì¶œ
def extract_info_from_filename(filename):
    base_filename = os.path.splitext(filename)[0]
    
    # íŒŒì¼ëª…ì„ ì–¸ë”ìŠ¤ì½”ì–´(_)ë¡œ ë¶„ë¦¬
    parts = base_filename.split('_')
    
    # ë§ˆì§€ë§‰ ë‘ ë¶€ë¶„ì´ í•™ë²ˆê³¼ ì´ë¦„ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
    if len(parts) >= 2:
        # ë§ˆì§€ë§‰ ë¶€ë¶„ì´ í•œê¸€ ì´ë¦„ì¸ì§€ í™•ì¸
        if re.match(r'^[ê°€-í£]{2,5}$', parts[-1]):
            student_name = parts[-1]
        else:
            # í•œê¸€ ì´ë¦„ íŒ¨í„´ ì°¾ê¸°
            name_match = re.search(r'[ê°€-í£]{2,5}', parts[-1])
            student_name = name_match.group() if name_match else "UnknownName"
        
        # ë’¤ì—ì„œ ë‘ ë²ˆì§¸ ë¶€ë¶„ì´ í•™ë²ˆì¸ì§€ í™•ì¸ (ìˆ«ìë¡œë§Œ êµ¬ì„±)
        if len(parts) >= 3 and re.match(r'^\d{6,10}$', parts[-2]):
            student_id = parts[-2]
        else:
            # í•™ë²ˆ íŒ¨í„´ ì°¾ê¸°
            id_match = re.search(r'\d{6,10}', base_filename)
            student_id = id_match.group() if id_match else "UnknownID"
            
        return student_name, student_id
    
    # ì–¸ë”ìŠ¤ì½”ì–´ ë¶„ë¦¬ë¡œ ì²˜ë¦¬ë˜ì§€ ì•ŠëŠ” ê²½ìš°ë¥¼ ìœ„í•œ backup ì²˜ë¦¬
    # í•™ë²ˆ ì¶”ì¶œ (6-10ìë¦¬ ìˆ«ì)
    id_match = re.search(r'\d{6,10}', base_filename)
    student_id = id_match.group() if id_match else "UnknownID"
    
    # ì´ë¦„ ì¶”ì¶œ (2-5ì í•œê¸€)
    name_match = re.search(r'[ê°€-í£]{2,5}', base_filename)
    student_name = name_match.group() if name_match else "UnknownName"
    
    return student_name, student_id

#ì—¬ëŸ¬ í•™ìƒ PDFë¥¼ ì½ê³ , ì´ë¦„/í•™ë²ˆ/ë‹µì•ˆ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥
def process_student_pdfs(pdf_files):
    answers, info = [], []
    for file in pdf_files:
        file.seek(0)
        file_bytes = file.read()
        text = extract_text_from_pdf(io.BytesIO(file_bytes))
        name, sid = extract_info_from_filename(file.name)
        if len(text.strip()) > 20:
            answers.append(text)
            info.append({'name': name, 'id': sid, 'text': text})

    st.session_state.student_answers_data = info
    return answers, info

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.markdown("## ğŸ“˜ ì±„ì  íë¦„")

    if st.button("1ï¸âƒ£ ë¬¸ì œ ì—…ë¡œë“œ ë° ì±„ì  ê¸°ì¤€ ìƒì„±"):
        st.session_state.step = 1
    if st.button("2ï¸âƒ£ í•™ìƒ ë‹µì•ˆ ì—…ë¡œë“œ ë° ë¬´ì‘ìœ„ ì±„ì "):
        st.session_state.step = 2
    if st.button("3ï¸âƒ£ êµìˆ˜ì í”¼ë“œë°± ì…ë ¥"):
        st.session_state.step = 3

    st.markdown("### ğŸ“ êµìˆ˜ì í”¼ë“œë°±", unsafe_allow_html=True)
    feedback = st.text_area("ì±„ì  ê¸°ì¤€ ìˆ˜ì • í”¼ë“œë°±", value=st.session_state.feedback_text, key="sidebar_feedback")
    
    # í”¼ë“œë°± í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
    st.session_state.feedback_text = feedback

    st.markdown("---")
    st.caption("ğŸš€ ë³¸ ì‹œìŠ¤í…œì€ **DPT íŒ€**ì´ ê°œë°œí•œ êµìˆ˜ì ì§€ì› ë„êµ¬ì…ë‹ˆë‹¤.")
    st.caption("ì±„ì  ê¸°ì¤€ ìˆ˜ë¦½ê³¼ ì¼ê´€ëœ ì±„ì ì„ ë•ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ì‚¬ìš©ë²• ì•ˆë‚´
with st.expander("â„¹ï¸ ì‚¬ìš©ë²• ë³´ê¸°"):
    st.markdown("""
### ğŸ“ ì‚¬ìš©ë²• ì•ˆë‚´

ì´ ì‹œìŠ¤í…œì€ êµìˆ˜ìì˜ ì±„ì  ì—…ë¬´ë¥¼ ë³´ì¡°í•˜ê¸° ìœ„í•´ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.  
ì•„ë˜ì˜ 3ë‹¨ê³„ë¥¼ ë”°ë¼ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤.

---

#### STEP 1: ë¬¸ì œ ì—…ë¡œë“œ ë° ì±„ì  ê¸°ì¤€ ìƒì„±
1. ë¬¸ì œ PDFë¥¼ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
2. `ğŸ“ ì±„ì  ê¸°ì¤€ ìƒì„±` ë²„íŠ¼ì„ í´ë¦­í•˜ë©´, GPTê°€ ìë™ìœ¼ë¡œ ì±„ì  ê¸°ì¤€ì„ ìƒì„±í•´ì¤ë‹ˆë‹¤.
3. ìƒì„±ëœ ê¸°ì¤€ì€ ë§ˆí¬ë‹¤ìš´ í‘œë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

#### STEP 2: í•™ìƒ ë‹µì•ˆ ì—…ë¡œë“œ ë° ë¬´ì‘ìœ„ ì±„ì 
1. ì—¬ëŸ¬ í•™ìƒì˜ PDF ë‹µì•ˆ íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
2. `ğŸ¯ ë¬´ì‘ìœ„ ì±„ì  ì‹¤í–‰` ë²„íŠ¼ì„ í´ë¦­í•˜ë©´, í•œ ëª…ì˜ í•™ìƒ ë‹µì•ˆì„ GPTê°€ ìë™ìœ¼ë¡œ ì±„ì í•´ì¤ë‹ˆë‹¤.
3. ì±„ì  ê²°ê³¼ëŠ” í•­ëª©ë³„ ì ìˆ˜ì™€ ê°„ë‹¨í•œ í”¼ë“œë°±ì´ í¬í•¨ëœ í‘œë¡œ ì¶œë ¥ë©ë‹ˆë‹¤.

---

#### STEP 3: êµìˆ˜ì í”¼ë“œë°± ì…ë ¥ ë° ì±„ì  ê¸°ì¤€ ìˆ˜ì •
1. ì‚¬ì´ë“œë°”ì— ìˆëŠ” `ğŸ“ êµìˆ˜ì í”¼ë“œë°±` ì…ë ¥ë€ì— ê°œì„ í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì‘ì„±í•©ë‹ˆë‹¤.
2. `â™»ï¸ í”¼ë“œë°± ë°˜ì˜` ë²„íŠ¼ì„ ëˆ„ë¥´ë©´, GPTê°€ ìˆ˜ì •ëœ ì±„ì  ê¸°ì¤€ì„ ìƒˆë¡œ ìƒì„±í•´ì¤ë‹ˆë‹¤.

---

ğŸ’¡ ì´ ì‹œìŠ¤í…œì€ ì±„ì  ê¸°ì¤€ ìˆ˜ë¦½ê³¼ ì¼ê´€ëœ í‰ê°€ë¥¼ ë„ì™€ì¤ë‹ˆë‹¤.  
ğŸš€ GPT-4o ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ê³  ìˆìœ¼ë©°, ì±„ì  ê²°ê³¼ëŠ” ì°¸ê³ ìš©ì…ë‹ˆë‹¤.
""")


# ë‹¨ê³„ ì•ˆë‚´ ë° ë²„íŠ¼
st.markdown(f"### í˜„ì¬ ë‹¨ê³„: STEP {st.session_state.step}")

# STEP 1 - ë¬¸ì œ ì—…ë¡œë“œ -> ì±„ì  ê¸°ì¤€ ìƒì„±
if st.session_state.step == 1:
    problem_pdf = st.file_uploader("ğŸ“„ ë¬¸ì œ PDF ì—…ë¡œë“œ", type="pdf", key="problem_upload")

    if problem_pdf:
        # PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë‚´ìš©ê³¼ íŒŒì¼ëª…ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        file_bytes = problem_pdf.read()
        st.session_state.problem_pdf_bytes = file_bytes
        st.session_state.problem_filename = problem_pdf.name
        text = extract_text_from_pdf(io.BytesIO(file_bytes))
        st.session_state.problem_text = text
        
        rubric_key = f"rubric_{problem_pdf.name}"

        st.subheader("ğŸ“ƒ ë¬¸ì œ ë‚´ìš©")
        st.write(text)

        # ì´ë¯¸ ìƒì„±ëœ ì±„ì  ê¸°ì¤€ì´ ìˆëŠ”ì§€ í™•ì¸
        if rubric_key not in st.session_state.generated_rubrics:
            prompt = f"""ë‹¤ìŒ ë¬¸ì œì— ëŒ€í•œ ì±„ì  ê¸°ì¤€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš” (ë°˜ë“œì‹œ **í•œê¸€**ë¡œ ì‘ì„±):

ë¬¸ì œ: {text}

ìš”êµ¬ì‚¬í•­:
1. í‘œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš” (ì •í™•íˆ '| ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |' í˜•ì‹ì˜ ë§ˆí¬ë‹¤ìš´ í‘œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”)
2. ê° í•­ëª©ì˜ ì„¸ë¶€ ê¸°ì¤€ì€ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
3. ì„¤ëª…ì€ ë°˜ë“œì‹œ **í•œê¸€**ë¡œ ì‘ì„±í•´ì•¼ í•˜ë©°, ì˜ì–´ í˜¼ìš© ì—†ì´ ì‘ì„±í•´ì£¼ì„¸ìš”
4. í‘œ ì•„ë˜ì— **ë°°ì  ì´í•©**ë„ í•¨ê»˜ ì‘ì„±í•´ì£¼ì„¸ìš”
5. ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ ë¬¸ë²•ì„ ì •í™•íˆ ì‚¬ìš©í•´ì£¼ì„¸ìš”, (ê° í–‰ ì‹œì‘ê³¼ ëì— |, í—¤ë” í–‰ ì•„ë˜ì— |---|---|---| í˜•ì‹ì˜ êµ¬ë¶„ì„ )

ì˜ˆì‹œ í˜•ì‹:
| ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |
|---------|-----|---------|
| í•­ëª© 1 | 5ì  | ì„¸ë¶€ ê¸°ì¤€ ì„¤ëª… |
| í•­ëª© 2 | 10ì  | ì„¸ë¶€ ê¸°ì¤€ ì„¤ëª… |

**ë°°ì  ì´í•©: 15ì **
"""
            if st.button("ğŸ“ ì±„ì  ê¸°ì¤€ ìƒì„±"):
                # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”í•˜ì—¬ ì´ì „ ëŒ€í™”ê°€ ì˜í–¥ì„ ì£¼ì§€ ì•Šë„ë¡ í•¨
                st.session_state.rubric_memory.clear()
                
                with st.spinner("GPTê°€ ì±„ì  ê¸°ì¤€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    result = rubric_chain.invoke({"input": prompt})
                    # ìƒì„±ëœ ì±„ì  ê¸°ì¤€ì„ ë³„ë„ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥
                    st.session_state.generated_rubrics[rubric_key] = result["text"]
                    st.success("âœ… ì±„ì  ê¸°ì¤€ ìƒì„± ì™„ë£Œ")
        else:
            if st.button("ğŸ“ ì±„ì  ê¸°ì¤€ ì¬ìƒì„±"):
                confirm = st.checkbox("âš ï¸ ì´ë¯¸ ìƒì„±ëœ ì±„ì  ê¸°ì¤€ì´ ìˆìŠµë‹ˆë‹¤. ì¬ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
                if confirm:
                    # ì—¬ê¸°ì„œëŠ” ëª…ì‹œì ìœ¼ë¡œ ì‚¬ìš©ìê°€ ì¬ìƒì„±ì„ ì›í•  ë•Œë§Œ ì²˜ë¦¬
                    prompt = f"""ë‹¤ìŒ ë¬¸ì œì— ëŒ€í•œ ì±„ì  ê¸°ì¤€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš” (ë°˜ë“œì‹œ **í•œê¸€**ë¡œ ì‘ì„±):

ë¬¸ì œ: {text}

ìš”êµ¬ì‚¬í•­:
1. í‘œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš” (ì •í™•íˆ '| ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |' í˜•ì‹ì˜ ë§ˆí¬ë‹¤ìš´ í‘œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”)
2. ê° í•­ëª©ì˜ ì„¸ë¶€ ê¸°ì¤€ì€ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
3. ì„¤ëª…ì€ ë°˜ë“œì‹œ **í•œê¸€**ë¡œ ì‘ì„±í•´ì•¼ í•˜ë©°, ì˜ì–´ í˜¼ìš© ì—†ì´ ì‘ì„±í•´ì£¼ì„¸ìš”
4. í‘œ ì•„ë˜ì— **ë°°ì  ì´í•©**ë„ í•¨ê»˜ ì‘ì„±í•´ì£¼ì„¸ìš”
5. ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ ë¬¸ë²•ì„ ì •í™•íˆ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤ (ê° í–‰ ì‹œì‘ê³¼ ëì— |, í—¤ë” í–‰ ì•„ë˜ì— |---|---|---| í˜•ì‹ì˜ êµ¬ë¶„ì„ )

ì˜ˆì‹œ í˜•ì‹:
| ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |
|---------|-----|---------|
| í•­ëª© 1 | 5ì  | ì„¸ë¶€ ê¸°ì¤€ ì„¤ëª… |
| í•­ëª© 2 | 10ì  | ì„¸ë¶€ ê¸°ì¤€ ì„¤ëª… |

**ë°°ì  ì´í•©: 15ì **
"""
                    st.session_state.rubric_memory.clear()
                    with st.spinner("GPTê°€ ì±„ì  ê¸°ì¤€ì„ ì¬ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                        result = rubric_chain.invoke({"input": prompt})
                        st.session_state.generated_rubrics[rubric_key] = result["text"]
                        st.success("âœ… ì±„ì  ê¸°ì¤€ ì¬ìƒì„± ì™„ë£Œ")

        # ì±„ì  ê¸°ì¤€ í‘œì‹œ
        if rubric_key in st.session_state.generated_rubrics:
            st.subheader("ğŸ“Š ì±„ì  ê¸°ì¤€")
            st.markdown(st.session_state.generated_rubrics[rubric_key])

#í•™ìƒ ë‹µì•ˆ -> ë¬´ì‘ìœ„ ì±„ì 
# STEP 2
elif st.session_state.step == 2:
    # ë¬¸ì œê°€ ì´ë¯¸ ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
    if st.session_state.problem_text and st.session_state.problem_filename:
        st.subheader("ğŸ“ƒ ë¬¸ì œ ë‚´ìš©")
        st.write(st.session_state.problem_text)
        
        rubric_key = f"rubric_{st.session_state.problem_filename}"
        if rubric_key in st.session_state.generated_rubrics:
            st.subheader("ğŸ“Š ì±„ì  ê¸°ì¤€")
            st.markdown(st.session_state.generated_rubrics[rubric_key])
        
        student_pdfs = st.file_uploader("ğŸ“¥ í•™ìƒ ë‹µì•ˆ PDF ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ)", type="pdf", accept_multiple_files=True, key="student_answers")
        
        if student_pdfs:
            if rubric_key not in st.session_state.generated_rubrics:
                st.warning("ì±„ì  ê¸°ì¤€ì´ ì—†ìŠµë‹ˆë‹¤. STEP 1ì—ì„œ ë¨¼ì € ì±„ì  ê¸°ì¤€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
            else:
                if st.button("ğŸ¯ ë¬´ì‘ìœ„ ì±„ì  ì‹¤í–‰"):
                    all_answers, info_list = process_student_pdfs(student_pdfs)
                    if not all_answers:
                        st.warning("ë‹µì•ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        idx = random.randint(0, len(all_answers) - 1)
                        selected_student = info_list[idx]
                        answer = all_answers[idx]

                        prompt = f"""ë‹¤ìŒì€ ì±„ì  ê¸°ì¤€ì…ë‹ˆë‹¤:
{st.session_state.generated_rubrics[rubric_key]}

ê·¸ë¦¬ê³  ì•„ë˜ëŠ” í•™ìƒ ë‹µì•ˆì…ë‹ˆë‹¤:
{answer}

ì´ ê¸°ì¤€ì— ë”°ë¼ ì±„ì  í‘œë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”:
ë°˜ë“œì‹œ ë‹¤ìŒê³¼ ê°™ì€ ì •í™•í•œ ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”:

| ì±„ì  í•­ëª© | ë°°ì  | GPT ì¶”ì²œ ì ìˆ˜ | ì„¸ë¶€ í‰ê°€ |
|---------|-----|------------|---------|
| í•­ëª© 1 | 5ì  | 4ì  | í‰ê°€ ë‚´ìš© |

í‘œ ì•„ë˜ì— ì´ì ê³¼ ê°„ë‹¨í•œ í”¼ë“œë°±ë„ ì‘ì„±í•´ì£¼ì„¸ìš”."""

                        with st.spinner("GPTê°€ ì±„ì  ì¤‘ì…ë‹ˆë‹¤..."):
                            # ì±„ì ì—ëŠ” ë©”ëª¨ë¦¬ê°€ í•„ìš”í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë³„ë„ ì²´ì¸ì„ ë§Œë“¤ì–´ ì‚¬ìš©
                            grading_chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template("{input}"))
                            result = grading_chain.invoke({"input": prompt})
                            st.session_state.last_grading_result = result["text"]
                            st.session_state.last_selected_student = selected_student
                            st.success("âœ… ì±„ì  ì™„ë£Œ")
    else:
        st.warning("ë¨¼ì € STEP 1ì—ì„œ ë¬¸ì œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        if st.button("STEP 1ë¡œ ì´ë™"):
            st.session_state.step = 1

    # ì±„ì  ê²°ê³¼ í‘œì‹œ
    if st.session_state.last_grading_result and st.session_state.last_selected_student:
        stu = st.session_state.last_selected_student
        st.subheader(f"ğŸ“‹ ì±„ì  ê²°ê³¼ - {stu['name']} ({stu['id']})")
        st.markdown(st.session_state.last_grading_result)

# STEP 3 : êµìˆ˜ì í”¼ë“œë°± -> ì±„ì  ê¸°ì¤€ ìˆ˜ì •
elif st.session_state.step == 3:
    # ë¬¸ì œê°€ ì´ë¯¸ ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
    if st.session_state.problem_text and st.session_state.problem_filename:
        rubric_key = f"rubric_{st.session_state.problem_filename}"
        
        if rubric_key not in st.session_state.generated_rubrics:
            st.warning("ì±„ì  ê¸°ì¤€ì´ ì—†ìŠµë‹ˆë‹¤. STEP 1ì—ì„œ ë¨¼ì € ì±„ì  ê¸°ì¤€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
            if st.button("STEP 1ë¡œ ì´ë™"):
                st.session_state.step = 1
        else:
            # ì›ë³¸ ì±„ì  ê¸°ì¤€ í‘œì‹œ
            st.subheader("ğŸ“Š ì›ë³¸ ì±„ì  ê¸°ì¤€")
            st.markdown(st.session_state.generated_rubrics[rubric_key])
            
            if st.button("â™»ï¸ í”¼ë“œë°± ë°˜ì˜"):
                feedback = st.session_state.feedback_text
                if not feedback.strip():
                    st.warning("í”¼ë“œë°±ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    prompt = f"""ê¸°ì¡´ ì±„ì  ê¸°ì¤€:
{st.session_state.generated_rubrics[rubric_key]}

í”¼ë“œë°±:
{feedback}

ìš”êµ¬ì‚¬í•­:
1. í‘œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš” (ì •í™•íˆ '| ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |' í˜•ì‹ì˜ ë§ˆí¬ë‹¤ìš´ í‘œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”)
2. ê° í•­ëª©ì˜ ì„¸ë¶€ ê¸°ì¤€ì€ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
3. ì„¤ëª…ì€ ë°˜ë“œì‹œ **í•œê¸€**ë¡œ ì‘ì„±í•´ì•¼ í•˜ë©°, ì˜ì–´ í˜¼ìš© ì—†ì´ ì‘ì„±í•´ì£¼ì„¸ìš”
4. í‘œ ì•„ë˜ì— **ë°°ì  ì´í•©**ë„ í•¨ê»˜ ì‘ì„±í•´ì£¼ì„¸ìš”
5. ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ ë¬¸ë²•ì„ ì •í™•íˆ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤ (ê° í–‰ ì‹œì‘ê³¼ ëì— |, í—¤ë” í–‰ ì•„ë˜ì— |---|---|---| í˜•ì‹ì˜ êµ¬ë¶„ì„ )

ì˜ˆì‹œ í˜•ì‹:
| ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |
|---------|-----|---------|
| í•­ëª© 1 | 5ì  | ì„¸ë¶€ ê¸°ì¤€ ì„¤ëª… |
| í•­ëª© 2 | 10ì  | ì„¸ë¶€ ê¸°ì¤€ ì„¤ëª… |

**ë°°ì  ì´í•©: 15ì **
"""
                
                    with st.spinner("GPTê°€ ê¸°ì¤€ì„ ìˆ˜ì • ì¤‘ì…ë‹ˆë‹¤..."):
                        # í”¼ë“œë°± ë°˜ì˜ì—ë„ ë³„ë„ ì²´ì¸ ì‚¬ìš©
                        feedback_chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template("{input}"))
                        updated = feedback_chain.invoke({"input": prompt})
                        st.session_state.modified_rubrics[rubric_key] = updated["text"]
                        st.success("âœ… ì±„ì  ê¸°ì¤€ ìˆ˜ì • ì™„ë£Œ")
                
            # ìˆ˜ì •ëœ ì±„ì  ê¸°ì¤€ì´ ìˆìœ¼ë©´ í‘œì‹œ
            if rubric_key in st.session_state.modified_rubrics:
                st.subheader("ğŸ†• ìˆ˜ì •ëœ ì±„ì  ê¸°ì¤€")
                st.markdown(st.session_state.modified_rubrics[rubric_key])
    else:
        st.warning("ë¨¼ì € STEP 1ì—ì„œ ë¬¸ì œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        if st.button("STEP 1ë¡œ ì´ë™"):
            st.session_state.step = 1
