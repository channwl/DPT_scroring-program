import streamlit as st
import PyPDF2
import random
import re
import io
import os
import json
import matplotlib.pyplot as plt
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import LLMChain
from langchain.memory import ConversationSummaryMemory
from langchain_core.prompts import PromptTemplate

# -------------------- ì´ˆê¸° ì„¤ì • --------------------
st.set_page_config(page_title="ìƒí˜¸ì‘ìš© ì±„ì  ì‹œìŠ¤í…œ", layout="wide")
st.title("ğŸ“ Interactiion AI ì±„ì  ì‹œìŠ¤í…œ")

llm = ChatOpenAI(
    openai_api_key=st.secrets["openai"]["API_KEY"],
    model_name="gpt-4o",
    temperature=0
)

# ì„¸ì…˜ ì´ˆê¸°í™”
def initialize():
    keys = {
        "step": 1,
        "rubric_memory": ConversationSummaryMemory(llm=llm, memory_key="history", return_messages=True),
        "problem_text": None,
        "problem_filename": None,
        "generated_rubrics": {},
        "student_answers_data": [],
        "feedback_text": "",
        "modified_rubrics": {},
        "highlighted_results": [],
        "last_grading_result": None,
        "last_selected_student": None,
        "all_grading_results": []
    }
    for k, v in keys.items():
        if k not in st.session_state:
            st.session_state[k] = v

initialize()

# -------------------- ìœ í‹¸ í•¨ìˆ˜ --------------------
def extract_text_from_pdf(pdf_data):
    reader = PyPDF2.PdfReader(io.BytesIO(pdf_data))
    return "".join([p.extract_text() or "" for p in reader.pages])

def extract_info_from_filename(filename):
    base = os.path.splitext(os.path.basename(filename))[0]
    sid_match = re.search(r'\d{6,10}', base)
    sid = sid_match.group() if sid_match else "UnknownID"
    name_candidates = [p for p in re.findall(r'[ê°€-í£]{2,5}', base) if p not in sid]
    for name in name_candidates:
        if name not in {"ê¸°ë§", "ì¤‘ê°„", "ê³¼ì œ", "ì‹œí—˜", "ìˆ˜ì—…", "ë ˆí¬íŠ¸", "ì œì¶œ", "ë‹µì•ˆ"}:
            return name, sid
    return "UnknownName", sid

def extract_total_score(grading_text):
    match = re.search(r'ì´ì [:ï¼š]?\s*(\d+)\s*ì ', grading_text)
    return int(match.group(1)) if match else None

def apply_highlight(answer_text, items):
    colors = ["#FFF59D", "#81C784", "#64B5F6", "#F48FB1"]
    for idx, item in enumerate(items):
        phrase = item.get("ê·¼ê±°ë¬¸ì¥")
        if phrase and phrase in answer_text:
            answer_text = answer_text.replace(
                phrase,
                f'<span style="background-color:{colors[idx % len(colors)]}; font-weight:bold;">{phrase}</span>'
            )
    return answer_text

# -------------------- ì‚¬ì´ë“œë°” --------------------
with st.sidebar:
    st.markdown("## ğŸ“˜ ì±„ì  íë¦„")
    if st.button("1ï¸âƒ£ ë¬¸ì œ ì—…ë¡œë“œ ë° ì±„ì  ê¸°ì¤€ ìƒì„±"):
        st.session_state.step = 1
    if st.button("2ï¸âƒ£ í•™ìƒ ë‹µì•ˆ ì—…ë¡œë“œ ë° ë¬´ì‘ìœ„ ì±„ì "):
        st.session_state.step = 2
    if st.button("3ï¸âƒ£ êµìˆ˜ì í”¼ë“œë°± ì…ë ¥"):
        st.session_state.step = 3
    if st.button("4ï¸âƒ£ ì „ì²´ í•™ìƒ ì¼ê´„ ì±„ì  + í•˜ì´ë¼ì´íŒ…"):
        st.session_state.step = 4

    st.markdown("### âœï¸ êµìˆ˜ì í”¼ë“œë°±")
    st.session_state.feedback_text = st.text_area("ì±„ì  ê¸°ì¤€ ìˆ˜ì • í”¼ë“œë°±", value=st.session_state.feedback_text)

    with st.expander("â„¹ï¸ ì‚¬ìš©ë²• ì•ˆë‚´ ë³´ê¸°"):
        st.markdown("""
**STEP 1:** ë¬¸ì œ ì—…ë¡œë“œ â†’ ì±„ì  ê¸°ì¤€ ìƒì„±  
**STEP 2:** í•™ìƒ ë‹µì•ˆ ì—…ë¡œë“œ â†’ ë¬´ì‘ìœ„ ì±„ì   
**STEP 3:** êµìˆ˜ì í”¼ë“œë°± â†’ ê¸°ì¤€ ìˆ˜ì •  
**STEP 4:** ì „ì²´ í•™ìƒ ìë™ ì±„ì  + í•˜ì´ë¼ì´íŒ… + ì ìˆ˜ ë¶„í¬
""")

# -------------------- STEP 1: ë¬¸ì œ ì—…ë¡œë“œ ë° ì±„ì  ê¸°ì¤€ ìƒì„± --------------------
if st.session_state.step == 1:
    problem_pdf = st.file_uploader("ğŸ“„ ë¬¸ì œ PDF ì—…ë¡œë“œ", type="pdf")
    if problem_pdf:
        file_bytes = problem_pdf.read()
        st.session_state.problem_pdf_bytes = file_bytes
        st.session_state.problem_filename = problem_pdf.name
        text = extract_text_from_pdf(file_bytes)
        st.session_state.problem_text = text
        rubric_key = f"rubric_{problem_pdf.name}"

        st.subheader("ğŸ“ƒ ë¬¸ì œ ë‚´ìš©")
        st.write(text)

        if rubric_key not in st.session_state.generated_rubrics:
            prompt = f"""
1. í‘œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš” (ì •í™•íˆ '| ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |' í˜•ì‹ì˜ ë§ˆí¬ë‹¤ìš´ í‘œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”)
2. ê° í•­ëª©ì˜ ì„¸ë¶€ ê¸°ì¤€ì€ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
3. ì„¤ëª…ì€ ë°˜ë“œì‹œ **í•œê¸€**ë¡œ ì‘ì„±í•´ì•¼ í•˜ë©°, ì˜ì–´ í˜¼ìš© ì—†ì´ ì‘ì„±í•´ì£¼ì„¸ìš”
4. í‘œ ì•„ë˜ì— **ë°°ì  ì´í•©**ë„ í•¨ê»˜ ì‘ì„±í•´ì£¼ì„¸ìš”
5. ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ ë¬¸ë²•ì„ ì •í™•íˆ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤ (ê° í–‰ ì‹œì‘ê³¼ ëì— |, í—¤ë” í–‰ ì•„ë˜ì— |---|---|---| í˜•ì‹ì˜ êµ¬ë¶„ì„ )

ì˜ˆì‹œ í˜•ì‹:
| ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |
|---------|-----|---------|
| í•­ëª© 1 | 5ì  | ì„¸ë¶€ ê¸°ì¤€ ì„¤ëª… |
| í•­ëª© 2 | 10ì  | ì„¸ë¶€ ê¸°ì¤€ ì„¤ëª… |

**ë°°ì  ì´í•©: 15ì **
"""
            if st.button("ğŸ“ ì±„ì  ê¸°ì¤€ ìƒì„±"):
                st.session_state.rubric_memory.clear()
                rubric_chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template("{input}"), memory=st.session_state.rubric_memory)
                with st.spinner("GPTê°€ ì±„ì  ê¸°ì¤€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    result = rubric_chain.invoke({"input": prompt})
                    st.session_state.generated_rubrics[rubric_key] = result["text"]
                    st.success("âœ… ì±„ì  ê¸°ì¤€ ìƒì„± ì™„ë£Œ")

        if rubric_key in st.session_state.generated_rubrics:
            st.subheader("ğŸ“Š ì±„ì  ê¸°ì¤€")
            st.markdown(st.session_state.generated_rubrics[rubric_key])

# -------------------- STEP 2: ë¬´ì‘ìœ„ ì±„ì  --------------------
elif st.session_state.step == 2:
    rubric_key = f"rubric_{st.session_state.problem_filename}"
    rubric_text = st.session_state.generated_rubrics.get(rubric_key)

    if not st.session_state.problem_text:
        st.warning("STEP 1ì—ì„œ ë¬¸ì œë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    else:
        st.subheader("ğŸ“ƒ ë¬¸ì œ ë‚´ìš©")
        st.write(st.session_state.problem_text)

        if rubric_text:
            st.subheader("ğŸ“Š ì±„ì  ê¸°ì¤€")
            st.markdown(rubric_text)

        student_pdfs = st.file_uploader("ğŸ“¥ í•™ìƒ ë‹µì•ˆ PDF ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", type="pdf", accept_multiple_files=True)

        if student_pdfs:
            st.session_state.student_answers_data.clear()
            answers = []
            for file in student_pdfs:
                file.seek(0)
                text = extract_text_from_pdf(file.read())
                name, sid = extract_info_from_filename(file.name)
                if len(text.strip()) > 20:
                    st.session_state.student_answers_data.append({"name": name, "id": sid, "text": text})
                    answers.append(text)

            if st.button("ğŸ¯ ë¬´ì‘ìœ„ ì±„ì  ì‹¤í–‰") and rubric_text:
                idx = random.randint(0, len(st.session_state.student_answers_data) - 1)
                stu = st.session_state.student_answers_data[idx]
                answer = stu["text"]
                prompt = f"""
ë‹¤ìŒì€ ì±„ì  ê¸°ì¤€ì…ë‹ˆë‹¤:
{rubric_text}

ê·¸ë¦¬ê³  ì•„ë˜ëŠ” í•™ìƒ ë‹µì•ˆì…ë‹ˆë‹¤:
{answer}

1. í‘œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš” (ì •í™•íˆ '| ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |' í˜•ì‹ì˜ ë§ˆí¬ë‹¤ìš´ í‘œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”)
2. ê° í•­ëª©ì˜ ì„¸ë¶€ ê¸°ì¤€ì€ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
3. ì„¤ëª…ì€ ë°˜ë“œì‹œ **í•œê¸€**ë¡œ ì‘ì„±í•´ì•¼ í•˜ë©°, ì˜ì–´ í˜¼ìš© ì—†ì´ ì‘ì„±í•´ì£¼ì„¸ìš”
4. í‘œ ì•„ë˜ì— **ë°°ì  ì´í•©**ë„ í•¨ê»˜ ì‘ì„±í•´ì£¼ì„¸ìš”
5. ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ ë¬¸ë²•ì„ ì •í™•íˆ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤ (ê° í–‰ ì‹œì‘ê³¼ ëì— |, í—¤ë” í–‰ ì•„ë˜ì— |---|---|---| í˜•ì‹ì˜ êµ¬ë¶„ì„ )

ì˜ˆì‹œ í˜•ì‹:
| ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |
|---------|-----|---------|
| í•­ëª© 1 | 5ì  | ì„¸ë¶€ ê¸°ì¤€ ì„¤ëª… |
| í•­ëª© 2 | 10ì  | ì„¸ë¶€ ê¸°ì¤€ ì„¤ëª… |

**ë°°ì  ì´í•©: 15ì **
"""
                grading_chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template("{input}"))
                with st.spinner("GPTê°€ ì±„ì  ì¤‘ì…ë‹ˆë‹¤..."):
                    result = grading_chain.invoke({"input": prompt})
                    st.session_state.last_grading_result = result["text"]
                    st.session_state.last_selected_student = stu
                    st.success("âœ… ì±„ì  ì™„ë£Œ")

    if st.session_state.last_grading_result and st.session_state.last_selected_student:
        s = st.session_state.last_selected_student
        st.subheader(f"ğŸ“‹ ì±„ì  ê²°ê³¼ - {s['name']} ({s['id']})")
        st.markdown(st.session_state.last_grading_result)

# -------------------- STEP 3: í”¼ë“œë°± ê¸°ë°˜ ì±„ì  ê¸°ì¤€ ìˆ˜ì • --------------------
elif st.session_state.step == 3:
    rubric_key = f"rubric_{st.session_state.problem_filename}"
    if not st.session_state.problem_text:
        st.warning("STEP 1ì—ì„œ ë¬¸ì œë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    elif rubric_key not in st.session_state.generated_rubrics:
        st.warning("STEP 1ì—ì„œ ì±„ì  ê¸°ì¤€ì„ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
    else:
        st.subheader("ğŸ“Š ì›ë³¸ ì±„ì  ê¸°ì¤€")
        st.markdown(st.session_state.generated_rubrics[rubric_key])
        if st.button("â™»ï¸ í”¼ë“œë°± ë°˜ì˜"):
            feedback = st.session_state.feedback_text
            prompt = f"""
ê¸°ì¡´ ì±„ì  ê¸°ì¤€:
{st.session_state.generated_rubrics[rubric_key]}

í”¼ë“œë°±:
{feedback}

1. í‘œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš” (ì •í™•íˆ '| ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |' í˜•ì‹ì˜ ë§ˆí¬ë‹¤ìš´ í‘œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”)
2. ê° í•­ëª©ì˜ ì„¸ë¶€ ê¸°ì¤€ì€ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
3. ì„¤ëª…ì€ ë°˜ë“œì‹œ **í•œê¸€**ë¡œ ì‘ì„±í•´ì•¼ í•˜ë©°, ì˜ì–´ í˜¼ìš© ì—†ì´ ì‘ì„±í•´ì£¼ì„¸ìš”
4. í‘œ ì•„ë˜ì— **ë°°ì  ì´í•©**ë„ í•¨ê»˜ ì‘ì„±í•´ì£¼ì„¸ìš”
5. ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ ë¬¸ë²•ì„ ì •í™•íˆ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤ (ê° í–‰ ì‹œì‘ê³¼ ëì— |, í—¤ë” í–‰ ì•„ë˜ì— |---|---|---| í˜•ì‹ì˜ êµ¬ë¶„ì„ )

ì˜ˆì‹œ í˜•ì‹:
| ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |
|---------|-----|---------|
| í•­ëª© 1 | 5ì  | ì„¸ë¶€ ê¸°ì¤€ ì„¤ëª… |
| í•­ëª© 2 | 10ì  | ì„¸ë¶€ ê¸°ì¤€ ì„¤ëª… |

**ë°°ì  ì´í•©: 15ì **
"""
            feedback_chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template("{input}"))
            with st.spinner("GPTê°€ ê¸°ì¤€ì„ ìˆ˜ì • ì¤‘ì…ë‹ˆë‹¤..."):
                updated = feedback_chain.invoke({"input": prompt})
                st.session_state.modified_rubrics[rubric_key] = updated["text"]
                st.success("âœ… ì±„ì  ê¸°ì¤€ ìˆ˜ì • ì™„ë£Œ")

        if rubric_key in st.session_state.modified_rubrics:
            st.subheader("ğŸ†• ìˆ˜ì •ëœ ì±„ì  ê¸°ì¤€")
            st.markdown(st.session_state.modified_rubrics[rubric_key])


# -------------------- STEP 4: ì „ì²´ ì±„ì  ë° í•˜ì´ë¼ì´íŒ… --------------------
if st.session_state.step == 4:
    if st.session_state.problem_text and st.session_state.problem_filename:
        rubric_key = f"rubric_{st.session_state.problem_filename}"
        rubric_text = st.session_state.generated_rubrics.get(rubric_key)

        if not rubric_text:
            st.warning("STEP 1ì—ì„œ ì±„ì  ê¸°ì¤€ì„ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
        elif not st.session_state.student_answers_data:
            st.warning("STEP 2ì—ì„œ í•™ìƒ ë‹µì•ˆì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        else:
            st.subheader("ğŸ“Š ì±„ì  ê¸°ì¤€")
            st.markdown(rubric_text)

            if st.button("ğŸ“¥ ì „ì²´ í•™ìƒ ì±„ì  ì‹¤í–‰"):
                grading_chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template("{input}"))
                st.session_state.highlighted_results.clear()
                with st.spinner("GPTê°€ ì „ì²´ í•™ìƒì„ ì±„ì  ì¤‘ì…ë‹ˆë‹¤..."):
                    for stu in st.session_state.student_answers_data:
                        name, sid, answer = stu["name"], stu["id"], stu["text"]
                        prompt = f"""
ë‹¤ìŒì€ ì±„ì  ê¸°ì¤€ì…ë‹ˆë‹¤:
{rubric_text}

ì•„ë˜ëŠ” í•™ìƒ ë‹µì•ˆì…ë‹ˆë‹¤:
{answer}

ë‹¤ìŒ JSON í¬ë§·ìœ¼ë¡œ ì±„ì  ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ì„¸ìš”:
```json
{{
  "total_score": ì •ìˆ˜,
  "feedback": "ì´í‰",
  "items": [
    {{ "í•­ëª©": "í•­ëª©ëª…", "ë°°ì ": ìˆ«ì, "ì ìˆ˜": ìˆ«ì, "í‰ê°€": "ë‚´ìš©", "ê·¼ê±°ë¬¸ì¥": "ë‹µì•ˆ ì¤‘ ì¼ë¶€ ë¬¸ì¥" }}
  ]
}}
```
                        """
                        result = grading_chain.invoke({"input": prompt})
                        try:
                            data = json.loads(result["text"])
                            highlighted = apply_highlight(answer, data.get("items", []))
                            st.session_state.highlighted_results.append({
                                "name": name,
                                "id": sid,
                                "score": data.get("total_score"),
                                "feedback": data.get("feedback"),
                                "highlighted_text": highlighted,
                                "items": data.get("items")
                            })
                        except Exception as e:
                            st.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                st.success("âœ… ì „ì²´ í•™ìƒ ì±„ì  ì™„ë£Œ")

            # ê²°ê³¼ ë° ë¶„í¬ í‘œì‹œ
            if st.session_state.highlighted_results:
                st.subheader("ğŸ“‹ ì „ì²´ í•™ìƒ ì±„ì  ê²°ê³¼")
                scores = []
                for r in st.session_state.highlighted_results:
                    st.markdown(f"### âœï¸ {r['name']} ({r['id']}) - ì´ì : {r['score']}ì ")
                    st.markdown(f"ğŸ—£ï¸ GPT í”¼ë“œë°±: {r['feedback']}")
                    st.markdown("**ğŸ§¾ í•™ìƒ ë‹µì•ˆ (í•˜ì´ë¼ì´íŒ… í‘œì‹œë¨):**", unsafe_allow_html=True)
                    st.markdown(r["highlighted_text"], unsafe_allow_html=True)
                    st.markdown("---")
                    if r["score"]:
                        scores.append(r["score"])

                if scores:
                    st.subheader("ğŸ“Š ì ìˆ˜ ë¶„í¬")
                    fig, ax = plt.subplots()
                    ax.hist(scores, bins=range(min(scores), max(scores)+2), edgecolor='black', align='left')
                    ax.set_xlabel("ì ìˆ˜")
                    ax.set_ylabel("í•™ìƒ ìˆ˜")
                    ax.set_title("GPT ì±„ì  ì ìˆ˜ ë¶„í¬")
                    st.pyplot(fig)
    else:
        st.warning("STEP 1ì—ì„œ ë¬¸ì œ ì—…ë¡œë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
