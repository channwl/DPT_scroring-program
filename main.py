import streamlit as st
import PyPDF2
import random
import re
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import LLMChain
from langchain.memory import ConversationSummaryMemory
from langchain_core.prompts import PromptTemplate

# GPT ì—°ê²°
llm = ChatOpenAI(
    openai_api_key=st.secrets["openai"]["API_KEY"],
    model_name="gpt-4o",
    temperature=0
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "rubric_memory" not in st.session_state:
    st.session_state.rubric_memory = ConversationSummaryMemory(
        llm=llm,
        memory_key="history",
        return_messages=True
    )

if "step" not in st.session_state:
    st.session_state.step = 1

# LLMChain êµ¬ì„±
prompt_template = PromptTemplate.from_template("{history}\n{input}")
rubric_chain = LLMChain(
    llm=llm,
    prompt=prompt_template,
    memory=st.session_state.rubric_memory
)

# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
def extract_text_from_pdf(pdf_file):
    pdf_reader = PyPDF2.PdfReader(pdf_file)
    text = ""
    for page in pdf_reader.pages:
        extracted = page.extract_text()
        if extracted:
            text += extracted
    return text

# íŒŒì¼ëª…ì—ì„œ ì´ë¦„/í•™ë²ˆ ì¶”ì¶œ
def extract_info_from_filename(filename):
    id_match = re.search(r"\d{8}", filename)
    name_match = re.findall(r"[ê°€-í£]{2,4}", filename)
    student_id = id_match.group() if id_match else "UnknownID"
    student_name = name_match[-1] if name_match else "UnknownName"
    return student_name, student_id

# ë‹µì•ˆ/í•™ìƒì •ë³´ ì¶”ì¶œ
def extract_answers_and_info_from_files(pdf_files):
    answers, student_info = [], []
    for pdf_file in pdf_files:
        text = extract_text_from_pdf(pdf_file)
        name, student_id = extract_info_from_filename(pdf_file.name)
        if len(text.strip()) > 20:
            answers.append(text)
            student_info.append({'name': name, 'id': student_id})
    return answers, student_info

# í—¤ë”
st.title("ğŸ“ AI êµìˆ˜ì ì±„ì  ì‹œìŠ¤í…œ")
st.markdown("ìë™ ì±„ì  | GPT-4o + LangChain")

# ì´ì „/ë‹¤ìŒ ë‹¨ê³„ ë²„íŠ¼
col1, col2 = st.columns(2)
with col1:
    if st.button("â¬…ï¸ ì´ì „ ë‹¨ê³„", disabled=st.session_state.step == 1):
        st.session_state.step -= 1
with col2:
    if st.button("â¡ï¸ ë‹¤ìŒ ë‹¨ê³„", disabled=st.session_state.step == 3):
        st.session_state.step += 1

st.markdown(f"## âœ… í˜„ì¬ ë‹¨ê³„: STEP {st.session_state.step}")

# STEP 1: ë¬¸ì œ ì—…ë¡œë“œ ë° ì±„ì  ê¸°ì¤€ ìƒì„±
if st.session_state.step == 1:
    st.header("ğŸ“Œ STEP 1: ë¬¸ì œ PDF ì—…ë¡œë“œ ë° ì±„ì  ê¸°ì¤€ ìƒì„±")
    problem_pdf = st.file_uploader("ë¬¸ì œ PDF ì—…ë¡œë“œ", type="pdf", key="problem_pdf")

    if problem_pdf:
        st.session_state.problem_pdf = problem_pdf
        problem_text = extract_text_from_pdf(problem_pdf)
        rubric_key = f"rubric_{problem_pdf.name}"

        st.subheader("ğŸ“„ ë¬¸ì œ ë‚´ìš©")
        st.write(problem_text)

        if rubric_key not in st.session_state:
            prompt = f"""ë‹¤ìŒ ë¬¸ì œì— ëŒ€í•œ ì±„ì  ê¸°ì¤€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”:
ë¬¸ì œ: {problem_text}
- í•­ëª©ë³„ë¡œ 'ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€' í˜•íƒœë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
- í‘œ ì•„ë˜ì— ë°°ì  í•©ê³„ë„ ì ì–´ì£¼ì„¸ìš”."""
            with st.spinner("GPTê°€ ì±„ì  ê¸°ì¤€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                rubric = rubric_chain.invoke({"input": prompt})
                st.session_state[rubric_key] = rubric["text"]
            st.success("âœ… ì±„ì  ê¸°ì¤€ ìƒì„± ì™„ë£Œ")

        if rubric_key in st.session_state:
            st.subheader("ğŸ“Š ìƒì„±ëœ ì±„ì  ê¸°ì¤€")
            st.write(st.session_state[rubric_key])

# STEP 2: ë¬´ì‘ìœ„ ì±„ì 
elif st.session_state.step == 2:
    st.header("ğŸ“Œ STEP 2: ë‹µì•ˆ ì—…ë¡œë“œ ë° ë¬´ì‘ìœ„ ì±„ì ")
    answers_pdfs = st.file_uploader("ë‹µì•ˆ PDF ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", type="pdf", accept_multiple_files=True)

    if "problem_pdf" not in st.session_state:
        st.info("ë¨¼ì € STEP 1ì—ì„œ ë¬¸ì œ PDFë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    elif answers_pdfs:
        problem_pdf = st.session_state.problem_pdf
        rubric_key = f"rubric_{problem_pdf.name}"

        if rubric_key not in st.session_state:
            st.warning("ì±„ì  ê¸°ì¤€ì´ ë¨¼ì € ìƒì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
        else:
            if st.button("ğŸ¯ ë¬´ì‘ìœ„ í•™ìƒ ì±„ì "):
                all_answers, student_info_list = extract_answers_and_info_from_files(answers_pdfs)

                if not all_answers:
                    st.warning("ë‹µì•ˆ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                else:
                    rand_idx = random.randint(0, len(all_answers) - 1)
                    selected_student = student_info_list[rand_idx]
                    random_answer = all_answers[rand_idx]

                    prompt = f"""ë‹¤ìŒì€ ì±„ì  ê¸°ì¤€ì…ë‹ˆë‹¤:
{st.session_state[rubric_key]}

ê·¸ë¦¬ê³  ì•„ë˜ëŠ” í•™ìƒ ë‹µì•ˆì…ë‹ˆë‹¤:
{random_answer}

ì´ ê¸°ì¤€ì— ë”°ë¼ ì±„ì  í‘œë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”:
| ì±„ì  í•­ëª© | ë°°ì  | GPT ì¶”ì²œ ì ìˆ˜ | ì„¸ë¶€ í‰ê°€ |
í‘œ ì•„ë˜ì— ì´ì ê³¼ ê°„ë‹¨í•œ í”¼ë“œë°±ë„ ì‘ì„±í•´ì£¼ì„¸ìš”."""

                    with st.spinner("GPTê°€ ì±„ì  ì¤‘ì…ë‹ˆë‹¤..."):
                        grading_result = rubric_chain.invoke({"input": prompt})
                        st.session_state.last_grading_result = grading_result["text"]
                        st.session_state.last_selected_student = selected_student

                    st.success("âœ… ì±„ì  ì™„ë£Œ!")

    # ìµœê·¼ ì±„ì  ê²°ê³¼ í‘œì‹œ
    if "last_grading_result" in st.session_state:
        student = st.session_state.last_selected_student
        st.subheader(f"ğŸ“‹ ìµœê·¼ ì±„ì  ê²°ê³¼ - {student['name']} ({student['id']})")
        st.write(st.session_state.last_grading_result)

# STEP 3: í”¼ë“œë°± ë°˜ì˜
elif st.session_state.step == 3:
    st.header("ğŸ“Œ STEP 3: êµìˆ˜ì í”¼ë“œë°± ë°˜ì˜")
    if "problem_pdf" not in st.session_state:
        st.info("ë¨¼ì € STEP 1ì—ì„œ ë¬¸ì œ PDFë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    else:
        problem_pdf = st.session_state.problem_pdf
        rubric_key = f"rubric_{problem_pdf.name}"

        if rubric_key not in st.session_state:
            st.warning("ì±„ì  ê¸°ì¤€ì´ ìƒì„±ë˜ì–´ì•¼ í”¼ë“œë°±ì„ ë°˜ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.subheader("ğŸ“ êµìˆ˜ì í”¼ë“œë°± ì…ë ¥")
            feedback_text = st.text_area("í”¼ë“œë°±ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: íŠ¹ì • í•­ëª©ì„ ë” ê°•ì¡°í•´ì£¼ì„¸ìš”)")

            if st.button("â™»ï¸ ì±„ì  ê¸°ì¤€ ìˆ˜ì •"):
                current_rubric = st.session_state[rubric_key]
                prompt = f"""ë‹¤ìŒì€ ê¸°ì¡´ ì±„ì  ê¸°ì¤€ì…ë‹ˆë‹¤:
{current_rubric}

ì•„ë˜ëŠ” êµìˆ˜ìì˜ í”¼ë“œë°±ì…ë‹ˆë‹¤:
{feedback_text}

ì´ í”¼ë“œë°±ì„ ë°˜ì˜í•´ì„œ ì±„ì  ê¸°ì¤€ì„ ìˆ˜ì •í•´ ì£¼ì„¸ìš”.
- í˜•ì‹ì€ 'ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€' í‘œ í˜•ì‹ìœ¼ë¡œ ìœ ì§€í•´ì£¼ì„¸ìš”."""

                with st.spinner("GPTê°€ ê¸°ì¤€ì„ ìˆ˜ì • ì¤‘ì…ë‹ˆë‹¤..."):
                    updated_rubric = rubric_chain.invoke({"input": prompt})
                    st.session_state[rubric_key] = updated_rubric["text"]

                st.success("âœ… ì±„ì  ê¸°ì¤€ ìˆ˜ì • ì™„ë£Œ")
                st.subheader("ğŸ†• ìˆ˜ì •ëœ ì±„ì  ê¸°ì¤€")
                st.write(updated_rubric["text"])
