import streamlit as st
import PyPDF2
import random
import re
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import LLMChain
from langchain.memory import ConversationSummaryMemory
from langchain_core.prompts import PromptTemplate

# GPT-4o ì—°ê²°
llm = ChatOpenAI(
    openai_api_key=st.secrets["openai"]["API_KEY"],
    model_name="gpt-4o",
    temperature=0
)

# LangChain Memory ì„¤ì •
if "rubric_memory" not in st.session_state:
    st.session_state.rubric_memory = ConversationSummaryMemory(
        llm=llm,
        memory_key="history",
        return_messages=True
    )

# PromptTemplate ì„¤ì •
prompt_template = PromptTemplate.from_template("{history}\n{input}")
rubric_chain = LLMChain(
    llm=llm,
    prompt=prompt_template,
    memory=st.session_state.rubric_memory
)

# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜
def extract_text_from_pdf(pdf_file):
    pdf_reader = PyPDF2.PdfReader(pdf_file)
    text = ""
    for page in pdf_reader.pages:
        page_text = page.extract_text()
        if page_text:
            text += page_text
    return text

# íŒŒì¼ëª…ì—ì„œ ì´ë¦„/í•™ë²ˆ ì¶”ì¶œ
def extract_info_from_filename(filename):
    id_match = re.search(r"\d{8}", filename)
    name_match = re.findall(r"[ê°€-í£]{2,4}", filename)
    student_id = id_match.group() if id_match else "UnknownID"
    student_name = name_match[-1] if name_match else "UnknownName"
    return student_name, student_id

# ë‹µì•ˆ ì¶”ì¶œ
def extract_answers_and_info_from_files(pdf_files):
    answers, student_info = [], []
    for pdf_file in pdf_files:
        text = extract_text_from_pdf(pdf_file)
        name, student_id = extract_info_from_filename(pdf_file.name)
        if len(text.strip()) > 20:
            answers.append(text)
            student_info.append({'name': name, 'id': student_id})
    return answers, student_info

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AI ì±„ì  ì‹œìŠ¤í…œ", layout="wide")

# ì‚¬ì´ë“œë°” êµ¬ì„±
with st.sidebar:
    st.title("ğŸ“˜ ì±„ì  íë¦„")
    st.markdown("1ï¸âƒ£ ë¬¸ì œ ì—…ë¡œë“œ ë° ì±„ì  ê¸°ì¤€ ìƒì„±")
    st.markdown("2ï¸âƒ£ í•™ìƒ ë‹µì•ˆ ì—…ë¡œë“œ ë° ë¬´ì‘ìœ„ ì±„ì ")
    st.markdown("3ï¸âƒ£ êµìˆ˜ì í”¼ë“œë°± ë°˜ì˜")

# ë©”ì¸ ì œëª©
st.title("ğŸ“ AI êµìˆ˜ì ì±„ì  ì‹œìŠ¤í…œ")

# STEP 1 - ë¬¸ì œ ì—…ë¡œë“œ ë° ì±„ì  ê¸°ì¤€ ìƒì„±
with st.expander("ğŸ“Œ STEP 1: ë¬¸ì œ PDF ì—…ë¡œë“œ ë° ì±„ì  ê¸°ì¤€ ìƒì„±", expanded=True):
    problem_pdf = st.file_uploader("ë¬¸ì œ PDF ì—…ë¡œë“œ", type="pdf", key="problem_pdf")
    
    if problem_pdf:
        st.session_state.problem_pdf = problem_pdf
        problem_text = extract_text_from_pdf(problem_pdf)
        rubric_key = f"rubric_{problem_pdf.name}"

        st.subheader("ğŸ“„ ë¬¸ì œ ë‚´ìš©")
        st.write(problem_text)

        if rubric_key not in st.session_state:
            prompt = f"""ë‹¤ìŒ ë¬¸ì œì— ëŒ€í•œ ì±„ì  ê¸°ì¤€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”:
ë¬¸ì œ: {problem_text}
- í•­ëª©ë³„ë¡œ 'ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€' í˜•íƒœë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
- í‘œ ì•„ë˜ì— ë°°ì  í•©ê³„ë„ ì ì–´ì£¼ì„¸ìš”."""
            with st.spinner("GPTê°€ ì±„ì  ê¸°ì¤€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                rubric = rubric_chain.invoke({"input": prompt})
                st.session_state[rubric_key] = rubric["text"]
            st.success("âœ… ì±„ì  ê¸°ì¤€ ìƒì„± ì™„ë£Œ")

        if rubric_key in st.session_state:
            st.subheader("ğŸ“Š ìƒì„±ëœ ì±„ì  ê¸°ì¤€")
            st.write(st.session_state[rubric_key])

# STEP 2 - ë¬´ì‘ìœ„ ì±„ì 
with st.expander("ğŸ¯ STEP 2: ë¬´ì‘ìœ„ í•™ìƒ ì±„ì  ê²°ê³¼", expanded=True):
    answers_pdfs = st.file_uploader("ë‹µì•ˆ PDF ì—…ë¡œë“œ (ë³µìˆ˜ ê°€ëŠ¥)", type="pdf", accept_multiple_files=True)

    if "problem_pdf" not in st.session_state:
        st.info("ë¨¼ì € STEP 1ì—ì„œ ë¬¸ì œ PDFë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    elif answers_pdfs:
        problem_pdf = st.session_state.problem_pdf
        rubric_key = f"rubric_{problem_pdf.name}"

        if rubric_key not in st.session_state:
            st.warning("ì±„ì  ê¸°ì¤€ì´ ë¨¼ì € ìƒì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
        else:
            if st.button("âœ… ë¬´ì‘ìœ„ ì±„ì  ì‹¤í–‰"):
                all_answers, student_info_list = extract_answers_and_info_from_files(answers_pdfs)

                if not all_answers:
                    st.warning("í•™ìƒ ë‹µì•ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    rand_idx = random.randint(0, len(all_answers) - 1)
                    selected_student = student_info_list[rand_idx]
                    random_answer = all_answers[rand_idx]

                    prompt = f"""ë‹¤ìŒì€ ì±„ì  ê¸°ì¤€ì…ë‹ˆë‹¤:
{st.session_state[rubric_key]}

ê·¸ë¦¬ê³  ì•„ë˜ëŠ” í•™ìƒ ë‹µì•ˆì…ë‹ˆë‹¤:
{random_answer}

ì´ ê¸°ì¤€ì— ë”°ë¼ ì±„ì  í‘œë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”:
| ì±„ì  í•­ëª© | ë°°ì  | GPT ì¶”ì²œ ì ìˆ˜ | ì„¸ë¶€ í‰ê°€ |
í‘œ ì•„ë˜ì— ì´ì ê³¼ ê°„ë‹¨í•œ í”¼ë“œë°±ë„ ì‘ì„±í•´ì£¼ì„¸ìš”."""

                    with st.spinner("GPTê°€ ì±„ì  ì¤‘ì…ë‹ˆë‹¤..."):
                        grading_result = rubric_chain.invoke({"input": prompt})
                        st.session_state["last_grading_result"] = grading_result["text"]
                        st.session_state["last_selected_student"] = selected_student
                    st.success("âœ… ì±„ì  ì™„ë£Œ!")

    if "last_grading_result" in st.session_state:
        student = st.session_state["last_selected_student"]
        st.subheader(f"ğŸ“‹ ìµœê·¼ ì±„ì  ê²°ê³¼ - {student['name']} ({student['id']})")
        st.write(st.session_state["last_grading_result"])

# STEP 3 - í”¼ë“œë°± ë°˜ì˜
with st.expander("ğŸ“ STEP 3: êµìˆ˜ì í”¼ë“œë°± ë°˜ì˜ ë° ê¸°ì¤€ ìˆ˜ì •", expanded=True):
    if "problem_pdf" not in st.session_state:
        st.info("ë¨¼ì € STEP 1ì—ì„œ ë¬¸ì œ PDFë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    else:
        problem_pdf = st.session_state.problem_pdf
        rubric_key = f"rubric_{problem_pdf.name}"

        if rubric_key not in st.session_state:
            st.warning("ì±„ì  ê¸°ì¤€ì´ ìƒì„±ë˜ì–´ì•¼ í”¼ë“œë°±ì„ ë°˜ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            feedback_text = st.text_area("í”¼ë“œë°±ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì´ í•­ëª©ì„ ë” ê°•ì¡°í•´ì£¼ì„¸ìš”)")

            if st.button("â™»ï¸ í”¼ë“œë°± ë°˜ì˜í•˜ì—¬ ì±„ì  ê¸°ì¤€ ìˆ˜ì •"):
                current_rubric = st.session_state[rubric_key]
                prompt = f"""ë‹¤ìŒì€ ê¸°ì¡´ ì±„ì  ê¸°ì¤€ì…ë‹ˆë‹¤:
{current_rubric}

ì•„ë˜ëŠ” êµìˆ˜ìì˜ í”¼ë“œë°±ì…ë‹ˆë‹¤:
{feedback_text}

ì´ í”¼ë“œë°±ì„ ë°˜ì˜í•´ì„œ ì±„ì  ê¸°ì¤€ì„ ìˆ˜ì •í•´ ì£¼ì„¸ìš”.
- í˜•ì‹ì€ 'ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€' í‘œ í˜•ì‹ìœ¼ë¡œ ìœ ì§€í•´ì£¼ì„¸ìš”."""

                with st.spinner("GPTê°€ ê¸°ì¤€ì„ ìˆ˜ì • ì¤‘ì…ë‹ˆë‹¤..."):
                    updated_rubric = rubric_chain.invoke({"input": prompt})
                    st.session_state[rubric_key] = updated_rubric["text"]

                st.success("âœ… ì±„ì  ê¸°ì¤€ ìˆ˜ì • ì™„ë£Œ")
                st.subheader("ğŸ†• ìˆ˜ì •ëœ ì±„ì  ê¸°ì¤€")
                st.write(updated_rubric["text"])
