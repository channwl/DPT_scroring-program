# step1_generate_rubric.py
# ì´ íŒŒì¼ì€ STEP 1: ë¬¸ì œ ì—…ë¡œë“œ ë° ì±„ì  ê¸°ì¤€ ìƒì„±ì„ ìœ„í•œ Streamlit UI ë° ì‹¤í–‰ ë¡œì§ì„ í¬í•¨í•©ë‹ˆë‹¤.

import streamlit as st
from utils.pdf_utils import extract_text_from_pdf
from langchain.chains import LLMChain
from langchain_core.prompts import PromptTemplate
from config.llm_config import get_llm


def generate_rubric(problem_text: str) -> str:
    prompt = f"""ë‹¹ì‹ ì€ ëŒ€í•™ ì‹œí—˜ ë¬¸ì œì— ëŒ€í•´ **ë¬¸ì œë³„ ì„¸ë¶„í™”ëœ ì±„ì  ê¸°ì¤€ì„ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ GPT**ì…ë‹ˆë‹¤.

ë‹¤ìŒ ë¬¸ì œ ë³¸ë¬¸ì„ ì½ê³ , ê° ë¬¸ì œì— ëŒ€í•´ ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ **ì±„ì  ê¸°ì¤€ ë§ˆí¬ë‹¤ìš´ í‘œ**ë¥¼ ìƒì„±í•˜ì„¸ìš”.

ì‘ì„± ì§€ì¹¨:
1. ë¬¸ì œ ë²ˆí˜¸ì™€ ë°°ì ì€ ë¬¸ì œ ë³¸ë¬¸ì—ì„œ **ì •í™•íˆ ì¶”ì¶œí•˜ì—¬ ë°˜ì˜**í•˜ì„¸ìš”.
   - ì˜ˆ: "(4 points)" â†’ "ë°°ì  ì´í•©: 4ì "
2. ê° ë¬¸ì œë§ˆë‹¤ ë³„ë„ì˜ ë§ˆí¬ë‹¤ìš´ í‘œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
3. í‘œ êµ¬ì¡°ëŠ” ì•„ë˜ í˜•ì‹ì„ ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”:
   | ì±„ì  í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |
   |---|---|---|
   | â€¦ | â€¦ | â€¦ |
4. í‘œ ì•„ë˜ì— ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë°°ì ì„ ì‘ì„±í•˜ì„¸ìš”:
   - **ë°°ì  ì´í•©: Xì **
5. ëª¨ë“  í‘œ ìƒì„±ì´ ëë‚œ í›„, ì „ì²´ ë°°ì  í•©ê³„ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”:
   - â†’ ì „ì²´ ë°°ì  ì´í•©: XXì 
6. ë¬¸ì œ ìˆ˜ë¥¼ ì˜ í™•ì¸í•˜ì—¬ ë¬¸ì œìˆ˜ì— ë§ê²Œ ì±„ì  ê¸°ì¤€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ì´ì œ ìœ„ ì§€ì¹¨ì„ ë”°ë¼ ì±„ì  ê¸°ì¤€ì„ ì‘ì„±í•˜ì„¸ìš”.
"""


    llm = get_llm()
    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template("{input}"))
    result = chain.invoke({"input": prompt})
    return result["text"]


def run_step1():
    st.subheader("ğŸ“„ STEP 1: ë¬¸ì œ ì—…ë¡œë“œ ë° ì±„ì  ê¸°ì¤€ ìƒì„±")

    problem_pdf = st.file_uploader("ğŸ“„ ë¬¸ì œ PDF ì—…ë¡œë“œ", type="pdf", key="problem_upload")

    if problem_pdf:
        file_bytes = problem_pdf.read()
        st.session_state.problem_pdf_bytes = file_bytes
        st.session_state.problem_filename = problem_pdf.name
        text = extract_text_from_pdf(file_bytes)
        st.session_state.problem_text = text

        rubric_key = f"rubric_{problem_pdf.name}"

        st.subheader("ğŸ“ƒ ë¬¸ì œ ë‚´ìš©")
        st.write(text)

        if rubric_key not in st.session_state.generated_rubrics:
            if st.button("ğŸ“ ì±„ì  ê¸°ì¤€ ìƒì„±"):
                st.session_state.rubric_memory.clear()
                with st.spinner("GPTê°€ ì±„ì  ê¸°ì¤€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    result = generate_rubric(text)
                    st.session_state.generated_rubrics[rubric_key] = result
                    st.success("âœ… ì±„ì  ê¸°ì¤€ ìƒì„± ì™„ë£Œ")
        else:
            if st.button("ğŸ“ ì±„ì  ê¸°ì¤€ ì¬ìƒì„±"):
                confirm = st.checkbox("âš ï¸ ì´ë¯¸ ìƒì„±ëœ ì±„ì  ê¸°ì¤€ì´ ìˆìŠµë‹ˆë‹¤. ì¬ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
                if confirm:
                    st.session_state.rubric_memory.clear()
                    with st.spinner("GPTê°€ ì±„ì  ê¸°ì¤€ì„ ì¬ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                        result = generate_rubric(text)
                        st.session_state.generated_rubrics[rubric_key] = result
                        st.success("âœ… ì±„ì  ê¸°ì¤€ ì¬ìƒì„± ì™„ë£Œ")

        if rubric_key in st.session_state.generated_rubrics:
            st.subheader("ğŸ“Š ì±„ì  ê¸°ì¤€")
            st.markdown(st.session_state.generated_rubrics[rubric_key])
