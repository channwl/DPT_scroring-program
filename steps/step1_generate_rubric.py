# step1_generate_rubric.py
# ì´ íŒŒì¼ì€ STEP 1: ë¬¸ì œ ì—…ë¡œë“œ ë° ì±„ì  ê¸°ì¤€ ìƒì„±ì„ ìœ„í•œ Streamlit UI ë° ì‹¤í–‰ ë¡œì§ì„ í¬í•¨í•©ë‹ˆë‹¤.

import streamlit as st
from utils.pdf_utils import extract_text_from_pdf
from langchain.chains import LLMChain
from langchain_core.prompts import PromptTemplate
from config.llm_config import get_llm
from langchain_core.prompts import PromptTemplate

def generate_rubric(problem_text: str) -> str:
    template = """
ë‹¹ì‹ ì€ ëŒ€í•™ ì‹œí—˜ ë¬¸ì œì— ëŒ€í•´ **ë¬¸ì œë³„ ì„¸ë¶„í™”ëœ ì±„ì  ê¸°ì¤€ì„ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ GPT**ì…ë‹ˆë‹¤.

ì•„ë˜ ë¬¸ì œ ë³¸ë¬¸ì„ ì½ê³ , ê° ë¬¸ì œì— ëŒ€í•´ **ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ ì±„ì  ê¸°ì¤€ ë§ˆí¬ë‹¤ìš´ í‘œ**ë¥¼ ìƒì„±í•˜ì„¸ìš”.

ğŸ“„ ë¬¸ì œ ë³¸ë¬¸:
{problem_text}

ğŸ“Œ ì‘ì„± ì§€ì¹¨:
1. ë¬¸ì œ ë²ˆí˜¸ì™€ ë°°ì ì€ ë¬¸ì œ ë³¸ë¬¸ì—ì„œ **ì •í™•íˆ ì¶”ì¶œí•˜ì—¬ ë°˜ì˜**í•˜ì„¸ìš”.
   ...
"""

    prompt = PromptTemplate(
        input_variables=["problem_text"],
        template=template
    )

    llm = get_llm()
    chain = LLMChain(llm=llm, prompt=prompt)
    result = chain.invoke({"problem_text": problem_text})

    return result["text"]

def run_step1():
    st.subheader("ğŸ“„ STEP 1: ë¬¸ì œ ì—…ë¡œë“œ ë° ì±„ì  ê¸°ì¤€ ìƒì„±")

    problem_pdf = st.file_uploader("ğŸ“„ ë¬¸ì œ PDF ì—…ë¡œë“œ", type="pdf", key="problem_upload")

    if problem_pdf:
        file_bytes = problem_pdf.read()
        st.session_state.problem_pdf_bytes = file_bytes
        st.session_state.problem_filename = problem_pdf.name
        text = extract_text_from_pdf(file_bytes)
        st.session_state.problem_text = text

        rubric_key = f"rubric_{problem_pdf.name}"

        st.subheader("ğŸ“ƒ ë¬¸ì œ ë‚´ìš©")
        st.write(text)

        if rubric_key not in st.session_state.generated_rubrics:
            if st.button("ğŸ“ ì±„ì  ê¸°ì¤€ ìƒì„±"):
                st.session_state.rubric_memory.clear()
                with st.spinner("GPTê°€ ì±„ì  ê¸°ì¤€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    result = generate_rubric(text)
                    st.session_state.generated_rubrics[rubric_key] = result
                    st.success("âœ… ì±„ì  ê¸°ì¤€ ìƒì„± ì™„ë£Œ")
        else:
            if st.button("ğŸ“ ì±„ì  ê¸°ì¤€ ì¬ìƒì„±"):
                confirm = st.checkbox("âš ï¸ ì´ë¯¸ ìƒì„±ëœ ì±„ì  ê¸°ì¤€ì´ ìˆìŠµë‹ˆë‹¤. ì¬ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
                if confirm:
                    st.session_state.rubric_memory.clear()
                    with st.spinner("GPTê°€ ì±„ì  ê¸°ì¤€ì„ ì¬ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                        result = generate_rubric(text)
                        st.session_state.generated_rubrics[rubric_key] = result
                        st.success("âœ… ì±„ì  ê¸°ì¤€ ì¬ìƒì„± ì™„ë£Œ")

        if rubric_key in st.session_state.generated_rubrics:
            st.subheader("ğŸ“Š ì±„ì  ê¸°ì¤€")
            st.markdown(st.session_state.generated_rubrics[rubric_key])
